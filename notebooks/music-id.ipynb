{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup\n",
    "\n",
    "Initial module setup."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import typing\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from eeg_auth_models_framework import data, pre_process, features, training, model\n",
    "from eeg_auth_models_framework.training.base import StratifiedSubjectData"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T00:03:04.881398900Z",
     "start_time": "2023-11-18T00:03:03.181898300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Constants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DATASET_SAMPLE_FREQ_HZ = 200\n",
    "DATA_CHANNEL_NAMES = ['T7','F8','Cz','P4']\n",
    "FREQUENCIES = [\n",
    "    pre_process.FrequencyBand(lower=8.0, upper=12.0, label='Alpha'),\n",
    "    pre_process.FrequencyBand(lower=12.0, upper=35.0, label='Beta'),\n",
    "    pre_process.FrequencyBand(lower=4.0, upper=8.0, label='Theta'),\n",
    "    pre_process.FrequencyBand(lower=35.0, upper=None, label='Gamma'),\n",
    "    pre_process.FrequencyBand(lower=None, upper=None, label='Raw'),\n",
    "]\n",
    "WINDOW_SIZE = 1200\n",
    "WINDOW_OVERLAP = 0.5\n",
    "K_FOLDS = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T00:03:04.896399100Z",
     "start_time": "2023-11-18T00:03:04.882899500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utilities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Types"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "SubjectDataMap = typing.Dict[str, pd.DataFrame]\n",
    "SubjectFramesMap = typing.Dict[str, typing.List[pd.DataFrame]]\n",
    "RawFrequencyDataMap = typing.Dict[str, typing.Union[mne.io.Raw, mne.io.RawArray]]\n",
    "SubjectFrameFeaturesMap = typing.Dict[str, typing.List[np.ndarray]]\n",
    "LabelledDataset = typing.Tuple[typing.List[np.ndarray], typing.List[int]]\n",
    "LabelledDatasetMap = typing.Dict[str, LabelledDataset]\n",
    "StratifiedData = typing.List[typing.Tuple[LabelledDataset, LabelledDataset]]\n",
    "StratifiedDatasetMap = typing.Dict[str, StratifiedData]\n",
    "MusicIDClassifiers = typing.Dict[str, RandomForestClassifier]\n",
    "T = typing.TypeVar('T')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T00:03:04.913898200Z",
     "start_time": "2023-11-18T00:03:04.897899Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Builder Configuration\n",
    "\n",
    "Configure data source, data reading method, data labelling method, and training process. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class MusicIDModelBuilder(model.ModelBuilder[MusicIDClassifiers]):\n",
    "    @property\n",
    "    def data_downloader(self):\n",
    "        return data.AuditoryDataDownloader()\n",
    "    \n",
    "    @property\n",
    "    def data_reader(self):\n",
    "        return data.AuditoryDataReader()\n",
    "    \n",
    "    @property\n",
    "    def labeller(self):\n",
    "        return training.SubjectDataLabeller()\n",
    "    \n",
    "    def run_training(self, labelled_data: typing.Dict[str, typing.List[StratifiedSubjectData]]):\n",
    "        subject_models: typing.Dict[str, RandomForestClassifier] = {\n",
    "            subject: RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                criterion='gini',\n",
    "                max_depth=10,\n",
    "                random_state=32\n",
    "            )\n",
    "            for subject in labelled_data\n",
    "        }\n",
    "        training_scores: typing.Dict[str, typing.List[float]] = {\n",
    "            subject: [] for subject in labelled_data\n",
    "        }\n",
    "        for subject in labelled_data:\n",
    "            print(f'TRAINING MODEL FOR SUBJECT: {subject}')\n",
    "            stratified_data = labelled_data[subject]\n",
    "            classifier = subject_models[subject]\n",
    "            iteration_count = 1\n",
    "            for segment in stratified_data:\n",
    "                print(f'FOLD: {iteration_count}')\n",
    "                classifier.fit(segment.train.x, segment.train.y)\n",
    "                training_scores[subject].append(\n",
    "                    classifier.score(segment.test.x, segment.test.y)\n",
    "                )\n",
    "                iteration_count += 1\n",
    "        print('TRAINING COMPLETE')\n",
    "        \n",
    "        return subject_models"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T00:03:04.927897700Z",
     "start_time": "2023-11-18T00:03:04.914398800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-Processing Steps\n",
    "\n",
    "Define pre-processing steps to be used in model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "pre_process_steps = [\n",
    "    pre_process.EEGBandpassFilterStep(\n",
    "        FREQUENCIES, \n",
    "        DATA_CHANNEL_NAMES, \n",
    "        DATASET_SAMPLE_FREQ_HZ\n",
    "    ),\n",
    "    pre_process.DataWindowStep(WINDOW_SIZE, WINDOW_OVERLAP)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T00:03:04.945413Z",
     "start_time": "2023-11-18T00:03:04.928397400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Extraction Steps\n",
    "\n",
    "Define feature extraction steps to be applied to the pre-processed data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "feature_extraction_steps = [\n",
    "    features.StatisticalFeatureExtractor([\n",
    "        features.StatisticalFeature.MIN,\n",
    "        features.StatisticalFeature.MAX,\n",
    "        features.StatisticalFeature.MEAN,\n",
    "        features.StatisticalFeature.ZERO_CROSSING_RATE\n",
    "    ])\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T00:03:04.958864Z",
     "start_time": "2023-11-18T00:03:04.943914Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training\n",
    "\n",
    "Execute training of authentication models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=40114\n",
      "    Range : 0 ... 40113 =      0.000 ...   200.565 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "TRAINING MODEL FOR SUBJECT: S01\n",
      "FOLD: 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous-multioutput and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m music_id_builder \u001B[38;5;241m=\u001B[39m MusicIDModelBuilder(\n\u001B[0;32m      2\u001B[0m     pre_process_steps,\n\u001B[0;32m      3\u001B[0m     feature_extraction_steps\n\u001B[0;32m      4\u001B[0m )\n\u001B[1;32m----> 5\u001B[0m \u001B[43mmusic_id_builder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mK_FOLDS\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Grad\\thesis\\Authentication-Baseline\\venv\\lib\\site-packages\\eeg_auth_models_framework\\model.py:103\u001B[0m, in \u001B[0;36mModelBuilder.train\u001B[1;34m(self, k_folds)\u001B[0m\n\u001B[0;32m    101\u001B[0m stratification_handler \u001B[38;5;241m=\u001B[39m SubjectDataStratificationHandler(k_folds)\n\u001B[0;32m    102\u001B[0m stratified_data \u001B[38;5;241m=\u001B[39m stratification_handler\u001B[38;5;241m.\u001B[39mget_k_folds_data(labelled_data)\n\u001B[1;32m--> 103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_training\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstratified_data\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[4], line 36\u001B[0m, in \u001B[0;36mMusicIDModelBuilder.run_training\u001B[1;34m(self, labelled_data)\u001B[0m\n\u001B[0;32m     33\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFOLD: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00miteration_count\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     34\u001B[0m         classifier\u001B[38;5;241m.\u001B[39mfit(segment\u001B[38;5;241m.\u001B[39mtrain\u001B[38;5;241m.\u001B[39mx, segment\u001B[38;5;241m.\u001B[39mtrain\u001B[38;5;241m.\u001B[39my)\n\u001B[0;32m     35\u001B[0m         training_scores[subject]\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m---> 36\u001B[0m             \u001B[43mclassifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscore\u001B[49m\u001B[43m(\u001B[49m\u001B[43msegment\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msegment\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     37\u001B[0m         )\n\u001B[0;32m     38\u001B[0m         iteration_count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTRAINING COMPLETE\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mD:\\Grad\\thesis\\Authentication-Baseline\\venv\\lib\\site-packages\\sklearn\\base.py:706\u001B[0m, in \u001B[0;36mClassifierMixin.score\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    681\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    682\u001B[0m \u001B[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001B[39;00m\n\u001B[0;32m    683\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;124;03m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001B[39;00m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    704\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m accuracy_score\n\u001B[1;32m--> 706\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43maccuracy_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Grad\\thesis\\Authentication-Baseline\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    206\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    207\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    208\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    209\u001B[0m         )\n\u001B[0;32m    210\u001B[0m     ):\n\u001B[1;32m--> 211\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    213\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    214\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    218\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    219\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    221\u001B[0m     )\n",
      "File \u001B[1;32mD:\\Grad\\thesis\\Authentication-Baseline\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:220\u001B[0m, in \u001B[0;36maccuracy_score\u001B[1;34m(y_true, y_pred, normalize, sample_weight)\u001B[0m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Accuracy classification score.\u001B[39;00m\n\u001B[0;32m    155\u001B[0m \n\u001B[0;32m    156\u001B[0m \u001B[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    216\u001B[0m \u001B[38;5;124;03m0.5\u001B[39;00m\n\u001B[0;32m    217\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    219\u001B[0m \u001B[38;5;66;03m# Compute accuracy for each possible representation\u001B[39;00m\n\u001B[1;32m--> 220\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m \u001B[43m_check_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    221\u001B[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001B[0;32m    222\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultilabel\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[1;32mD:\\Grad\\thesis\\Authentication-Baseline\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001B[0m, in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     90\u001B[0m     y_type \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(y_type) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 93\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m     94\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClassification metrics can\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt handle a mix of \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m targets\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m     95\u001B[0m             type_true, type_pred\n\u001B[0;32m     96\u001B[0m         )\n\u001B[0;32m     97\u001B[0m     )\n\u001B[0;32m     99\u001B[0m \u001B[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001B[39;00m\n\u001B[0;32m    100\u001B[0m y_type \u001B[38;5;241m=\u001B[39m y_type\u001B[38;5;241m.\u001B[39mpop()\n",
      "\u001B[1;31mValueError\u001B[0m: Classification metrics can't handle a mix of continuous-multioutput and binary targets"
     ]
    }
   ],
   "source": [
    "music_id_builder = MusicIDModelBuilder(\n",
    "    pre_process_steps,\n",
    "    feature_extraction_steps\n",
    ")\n",
    "music_id_builder.train(K_FOLDS) # FIXME: breaks with error \"classification metrics can't handle a mix of continuous-multioutput and binary targets\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T00:03:09.266756500Z",
     "start_time": "2023-11-18T00:03:04.958864Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
