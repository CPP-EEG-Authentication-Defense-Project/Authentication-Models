{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup\n",
    "\n",
    "Initial module setup."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import bs4\n",
    "import copy\n",
    "import dataclasses\n",
    "import pathlib\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import re\n",
    "import mne.io\n",
    "import requests\n",
    "import pandas as pd\n",
    "import typing\n",
    "import mne\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T02:53:02.288346700Z",
     "start_time": "2023-09-23T02:53:02.257846200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Structures"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class FrequencyBand:\n",
    "    lower: typing.Optional[float]\n",
    "    upper: typing.Optional[float]\n",
    "    label: str"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T02:53:02.296847200Z",
     "start_time": "2023-09-23T02:53:02.271345800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Constants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "DATASET_URL = 'https://physionet.org/files/auditory-eeg/1.0.0/Segmented_Data/'\n",
    "DATASET_SAMPLE_FREQ_HZ = 200\n",
    "DATA_CHANNEL_NAMES = ['T7','F8','Cz','P4']\n",
    "RAW_FREQUENCY = 'Raw'\n",
    "FREQUENCIES = [\n",
    "    FrequencyBand(lower=8.0, upper=12.0, label='Alpha'),\n",
    "    FrequencyBand(lower=12.0, upper=35.0, label='Beta'),\n",
    "    FrequencyBand(lower=4.0, upper=8.0, label='Theta'),\n",
    "    FrequencyBand(lower=35.0, upper=None, label='Gamma')\n",
    "]\n",
    "TRAINING_SPLIT_RATIO = 0.8\n",
    "FEATURE_MIN = 'Min'\n",
    "FEATURE_MAX = 'Max'\n",
    "FEATURE_MEAN = 'Mean'\n",
    "FEATURE_ZCR = 'ZCR'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T02:53:02.301845500Z",
     "start_time": "2023-09-23T02:53:02.291346500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utilities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Types"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "SubjectDataMap = typing.Dict[str, pd.DataFrame]\n",
    "SubjectFramesMap = typing.Dict[str, typing.List[pd.DataFrame]]\n",
    "RawFrequencyDataMap = typing.Dict[str, typing.Union[mne.io.Raw, mne.io.RawArray]]\n",
    "SubjectFrameFeaturesMap = typing.Dict[str, typing.List[np.ndarray]]\n",
    "LabelledDataset = typing.Tuple[typing.List[np.ndarray], typing.List[int]]\n",
    "LabelledDatasetMap = typing.Dict[str, LabelledDataset]\n",
    "T = typing.TypeVar('T')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T02:53:02.320847500Z",
     "start_time": "2023-09-23T02:53:02.301845500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def retrieve_dataset() -> pathlib.Path:\n",
    "    \"\"\"\n",
    "    Downloads (if necessary) the dataset and retrieves the path to the root of the dataset files directory.\n",
    "\n",
    "    :return: The path object pointing to the dataset directory.\n",
    "    \"\"\"\n",
    "    data_directory = _get_data_directory()\n",
    "    if data_directory.exists():\n",
    "        return data_directory\n",
    "    data_directory.mkdir(exist_ok=True)\n",
    "    _download_dataset(data_directory)\n",
    "    return data_directory\n",
    "\n",
    "\n",
    "def _get_data_directory() -> pathlib.Path:\n",
    "    \"\"\"\n",
    "    Helper function which generates the path to the data directory.\n",
    "\n",
    "    :return: The data directory path object.\n",
    "    \"\"\"\n",
    "    return pathlib.Path().resolve().parent / 'data'\n",
    "\n",
    "\n",
    "def _download_dataset(target_path: pathlib.Path):\n",
    "    \"\"\"\n",
    "    Initiates download of the dataset and saves all files into the given target path directory.\n",
    "\n",
    "    :param target_path: The target path directory.\n",
    "    \"\"\"\n",
    "    with requests.get(DATASET_URL) as listing_page:\n",
    "        listing_soup = bs4.BeautifulSoup(\n",
    "            listing_page.content,\n",
    "            features='html.parser'\n",
    "        )\n",
    "        _download_files_in_listing(target_path, listing_soup)\n",
    "\n",
    "\n",
    "def _download_files_in_listing(target_path: pathlib.Path, listing_soup: bs4.BeautifulSoup):\n",
    "    \"\"\"\n",
    "    Helper function which iterates over all file links in the given BeautifulSoup object and downloads each file into\n",
    "    the target path's directory.\n",
    "\n",
    "    :param target_path: The target path directory.\n",
    "    :param listing_soup: The BeautifulSoup object to use to find download links.\n",
    "    \"\"\"\n",
    "    experiment_1_data_pattern = re.compile(r's\\d{2}_ex05\\.csv')\n",
    "    \n",
    "    for file_link in listing_soup.find_all('a'):\n",
    "        file_href = file_link.get('href')\n",
    "        if file_href and experiment_1_data_pattern.match(file_href):\n",
    "            file_path = target_path / file_href\n",
    "            file_url = urllib.parse.urljoin(DATASET_URL, file_href)\n",
    "            _download_url_to_file(file_path, file_url)\n",
    "\n",
    "\n",
    "def _download_url_to_file(file_path: pathlib.Path, url: str):\n",
    "    \"\"\"\n",
    "    Downloads the given URLs remote content to the given file path.\n",
    "\n",
    "    :param file_path: The file path to download to.\n",
    "    :param url: The URL to download from.\n",
    "    \"\"\"\n",
    "    with requests.get(url) as response:\n",
    "        with open(file_path, 'wb') as out_file:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                out_file.write(chunk)\n",
    "                \n",
    "\n",
    "def read_data(target_path: pathlib.Path) -> SubjectDataMap:\n",
    "    \"\"\"\n",
    "    Reads all data files in the given directory path and generates a structure of dataframes.\n",
    "    \n",
    "    :param target_path: The target directory path.\n",
    "    :return: A map of dataframes, where the key is an identifier for the file and the value is the dataframe.\n",
    "    \"\"\"\n",
    "    loaded_data_map = {}\n",
    "    \n",
    "    for data_file in target_path.iterdir():\n",
    "        if data_file.suffix == '.csv':\n",
    "            subject_identifier = _get_subject_identifier(data_file.name)\n",
    "            dataframe = pd.read_csv(data_file, index_col=0, header=0)\n",
    "            loaded_data_map[subject_identifier] = dataframe\n",
    "    \n",
    "    return loaded_data_map\n",
    "\n",
    "\n",
    "def _get_subject_identifier(data_file_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Helper function which parses a subject identifier from a data file name.\n",
    "    \n",
    "    :param data_file_name: The file name to parse. \n",
    "    :return: A subject identifier.\n",
    "    :raises ValueError: If the identifier could not be parsed.\n",
    "    \"\"\"\n",
    "    identifier_pattern = re.compile(r'(?P<identifier>s\\d{2})')\n",
    "    search_result = re.search(identifier_pattern, data_file_name)\n",
    "    identifier = search_result.group('identifier')\n",
    "    if not identifier:\n",
    "        raise ValueError(f'Unable to parse subject identifier from file: \"{data_file_name}\"')\n",
    "    return identifier.upper()\n",
    "    \n",
    "    \n",
    "def window_dataset(dataframe_map: SubjectDataMap) -> SubjectFramesMap:\n",
    "    \"\"\"\n",
    "    Windows the given data map, using a window size of 1,200 and an overlap of 50%.\n",
    "    \n",
    "    :param dataframe_map: The data map.\n",
    "    :return: The windowed data map.\n",
    "    \"\"\"\n",
    "    window_size = 1200\n",
    "    overlap = 0.5\n",
    "    windowed_data = {}\n",
    "    \n",
    "    for identifier, dataframe in dataframe_map.items():\n",
    "        windowed_data[identifier] = _window_dataframe(dataframe, window_size, overlap)\n",
    "    \n",
    "    return windowed_data\n",
    "\n",
    "\n",
    "def _window_dataframe(dataframe: pd.DataFrame, size: int, overlap: float) -> typing.List[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Create a series of windows from the given dataframe.\n",
    "    \n",
    "    :param dataframe: The dataframe to window.\n",
    "    :param size: The size of the windows to create.\n",
    "    :param overlap: The percentage overlap (e.g., 0.5) of the windows.\n",
    "    :return: The windowed data.\n",
    "    \"\"\"\n",
    "    windowed_data = []\n",
    "    start = 0\n",
    "    end = size\n",
    "    \n",
    "    while end <= len(dataframe):\n",
    "        window = dataframe[start:end]\n",
    "        windowed_data.append(window)\n",
    "        \n",
    "        start += int(size * (1 - overlap))\n",
    "        end += int(size * (1 - overlap))\n",
    "    \n",
    "    return windowed_data\n",
    "    \n",
    "    \n",
    "def filter_subject_data(subject_data: SubjectDataMap) -> SubjectDataMap:\n",
    "    \"\"\"\n",
    "    Applies filtration to all the dataframes for each subject in the given data map.\n",
    "    \n",
    "    :param subject_data: the subject data to filter.\n",
    "    :return: a new data map, wherein the keys are the subject identifiers and the values are the\n",
    "             filtered data.\n",
    "    \"\"\"\n",
    "    data_windows_filtered = {}\n",
    "    \n",
    "    for identifier, data_to_filter in subject_data.items():\n",
    "        mne_data = convert_dataframe_to_mne(data_to_filter)\n",
    "        data_windows_filtered[identifier] = _retrieve_target_bands(mne_data)\n",
    "        \n",
    "    return data_windows_filtered\n",
    "            \n",
    "            \n",
    "def _retrieve_target_bands(mne_data: mne.io.RawArray) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieves a set of frequency bands from the given MNE data. A raw band is included in the result.\n",
    "    The result is formatted as a single DataFrame, wherein each column is a channel / frequency band\n",
    "    combination.\n",
    "    \n",
    "    :param mne_data: The MNE data to retrieve target bands from.\n",
    "    :return: Target band data, per channel and frequency band, in a single DataFrame.\n",
    "    \"\"\"\n",
    "    bands_map: RawFrequencyDataMap = {}\n",
    "    \n",
    "    # Retrieve the different frequency bands from the original data\n",
    "    for frequency in FREQUENCIES:\n",
    "        filtered_data = copy.deepcopy(mne_data)\n",
    "        filtered_data: mne.io.Raw = filtered_data.filter(\n",
    "            l_freq=frequency.lower,\n",
    "            h_freq=frequency.upper,\n",
    "            verbose=False,\n",
    "            l_trans_bandwidth=1,\n",
    "            h_trans_bandwidth=1\n",
    "        )\n",
    "        bands_map[frequency.label] = filtered_data\n",
    "    # Retain a \"raw\" frequency band\n",
    "    raw_data = copy.deepcopy(mne_data)\n",
    "    bands_map[RAW_FREQUENCY] = raw_data\n",
    "    \n",
    "    return _map_channel_frequencies(bands_map)\n",
    "    \n",
    "    \n",
    "def _map_channel_frequencies(bands_map: RawFrequencyDataMap) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a single DataFrame wherein each column is a channel / frequency band combination.\n",
    "    For example, if there was only one channel (e.g., T7) and two frequency bands (e.g., Alpha, Beta) then\n",
    "    the columns would be: \n",
    "        \"T7.Alpha\", \"T7.Beta\"\n",
    "    \n",
    "    :param bands_map: The raw frequency data in a map, \n",
    "                      where each key is a frequency type and each value is a Dataframe of frequency data.  \n",
    "    :return: The DataFrame of channel / frequency band data.\n",
    "    \"\"\"\n",
    "    frequency_data: typing.Dict[str, np.ndarray] = {}\n",
    "    \n",
    "    for channel in DATA_CHANNEL_NAMES:\n",
    "        for frequency_type in bands_map:\n",
    "            channel_data: pd.DataFrame = bands_map[frequency_type].to_data_frame(picks=channel)\n",
    "            frequency_data[f'{channel}.{frequency_type}'] = channel_data[channel].to_numpy()\n",
    "    \n",
    "    return pd.DataFrame(frequency_data)\n",
    "    \n",
    "    \n",
    "def convert_dataframe_to_mne(dataframe: pd.DataFrame) -> mne.io.RawArray:\n",
    "    \"\"\"\n",
    "    Converts the given dataframe over to Python-MNE format.\n",
    "    \n",
    "    :param dataframe: The dataframe to convert.\n",
    "    :return: A Python-MNE data array.\n",
    "    \"\"\"\n",
    "    transposed_dataframe = dataframe.transpose(copy=True)\n",
    "    data_info = mne.create_info(DATA_CHANNEL_NAMES, DATASET_SAMPLE_FREQ_HZ, ch_types='eeg')\n",
    "    return mne.io.RawArray(transposed_dataframe.to_numpy(), data_info)\n",
    "\n",
    "\n",
    "def extract_features(filtered_data: SubjectFramesMap) -> SubjectFrameFeaturesMap:\n",
    "    \"\"\"\n",
    "    Extracts features from the given filtered frame data (assumed to be mapped by subject). \n",
    "    The resulting map has each subject as a key, and a list of feature vectors as the value (where\n",
    "    each feature vector was generated from one frame).\n",
    "    \n",
    "    :param filtered_data: The filtered frame data.\n",
    "    :return: A map of subject windowed feature vectors.\n",
    "    \"\"\"\n",
    "    features_map = {}\n",
    "    \n",
    "    for key in filtered_data:\n",
    "        frame_features = []\n",
    "        for frame in filtered_data[key]:\n",
    "            frame_features.append(_extract_features_from_frame(frame))\n",
    "        features_map[key] = frame_features\n",
    "    \n",
    "    return features_map\n",
    "\n",
    "\n",
    "def _extract_features_from_frame(frame_channel_data: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extracts a feature vector from the given frame data.\n",
    "    \n",
    "    :param frame_channel_data: The frame data, with the channels / frequency bands by column.\n",
    "    :return: A single array of features.\n",
    "    \"\"\"\n",
    "    extracted_feature_chunks = []\n",
    "    \n",
    "    for frame_column in frame_channel_data:\n",
    "        frame_data_column = frame_channel_data[frame_column]\n",
    "        minimum_data = frame_data_column.min()\n",
    "        maximum_data = frame_data_column.max()\n",
    "        mean_data = frame_data_column.mean()\n",
    "        zero_crossing_rate_data = frame_data_column.agg(_get_zero_crossing_rate)\n",
    "        feature_vector_chunk = np.array(\n",
    "            [minimum_data, maximum_data, mean_data, zero_crossing_rate_data]\n",
    "        )\n",
    "        extracted_feature_chunks.append(feature_vector_chunk)\n",
    "    \n",
    "    return np.array(extracted_feature_chunks).flatten()\n",
    "\n",
    "\n",
    "def _get_zero_crossing_rate(data_to_process: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Helper function which calculates a Zero Crossing Rate (ZCR) for the given\n",
    "    Pandas Series.\n",
    "    \n",
    "    :param data_to_process: The series to retrieve the ZCR for.\n",
    "    :return: The ZCR.\n",
    "    \"\"\"\n",
    "    row_array = data_to_process.to_numpy()\n",
    "    zero_crossings = _count_zero_crossings(row_array)\n",
    "    return zero_crossings / len(row_array)\n",
    "    \n",
    "    \n",
    "def _count_zero_crossings(target_array: np.ndarray) -> int:\n",
    "    \"\"\"\n",
    "    Helper function which counts the number of zero crossings in a given array.\n",
    "    \n",
    "    see: https://stackoverflow.com/a/30281079/13261549\n",
    "    \n",
    "    :param target_array: The array to count zero crossings from.\n",
    "    :return: The number of zero crossings in the array.\n",
    "    \"\"\"\n",
    "    return ((target_array[:-1] * target_array[1:]) < 0).sum()\n",
    "\n",
    "\n",
    "def get_labelled_dataset_map(map_to_convert: SubjectFrameFeaturesMap) -> LabelledDatasetMap:\n",
    "    \"\"\"\n",
    "    Helper function which converts the given subject features map to a map of labelled datasets.\n",
    "    \n",
    "    :param map_to_convert: the original subject features map to convert. \n",
    "    :return: a new map wherein the keys are subject identifiers and the values are labelled datasets.\n",
    "    \"\"\"\n",
    "    converted_map = {}\n",
    "    \n",
    "    for key in map_to_convert:\n",
    "        converted_map[key] = _get_x_y_labelled_dataset(map_to_convert, key)\n",
    "        \n",
    "    return converted_map\n",
    "\n",
    "\n",
    "def _get_x_y_labelled_dataset(map_to_label: SubjectFrameFeaturesMap, target_subject_key: str) -> LabelledDataset:\n",
    "    \"\"\"\n",
    "    Utility function which generates a list of samples and a list of associated labels, based on the given target subject\n",
    "    (i.e., '1' indicates the sample is for the target, '0' otherwise).\n",
    "    \n",
    "    \n",
    "    :param map_to_label: a map wherein the keys are subject identifiers and the values are lists of data samples.\n",
    "    :param target_subject_key: the key to use to tailor the dataset to.\n",
    "    :return: a Tuple containing samples, and the corresponding labels.\n",
    "    \"\"\"\n",
    "    if target_subject_key not in map_to_label:\n",
    "        raise KeyError(f'Key \"{target_subject_key}\" not found in data map!')\n",
    "    label_translation_map = {}\n",
    "    samples_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    for key in map_to_label:\n",
    "        label_id = 1 if key == target_subject_key else 0\n",
    "        label_translation_map[key] = label_id\n",
    "        for subject_frame_sample in map_to_label[key]:\n",
    "            samples_list.append(subject_frame_sample)\n",
    "            labels_list.append(label_id)\n",
    "    \n",
    "    return samples_list, labels_list\n",
    "        \n",
    "\n",
    "def get_sample_value_from_map(map_to_sample: typing.Dict[str, T]) -> T:\n",
    "    \"\"\"\n",
    "    Helper function which retrieves a sample dataframe from the given map of data.\n",
    "    \n",
    "    :param map_to_sample: The data map to get a sample from. \n",
    "    \"\"\"\n",
    "    return next(iter(map_to_sample.values()))\n",
    "\n",
    "\n",
    "def print_info_about_subjects(map_to_summarize: SubjectDataMap):\n",
    "    \"\"\"\n",
    "    Helper function which prints some basic information about the\n",
    "    subjects in a data map.\n",
    "    \n",
    "    :param map_to_summarize: the map to print info from.\n",
    "    \"\"\"\n",
    "    print('SUBJECT DATA')\n",
    "    print(f'Number of subjects: {len(map_to_summarize.keys())}')\n",
    "    print('Subject identifiers:')\n",
    "    for key in map_to_summarize:\n",
    "        print(key)\n",
    "\n",
    "\n",
    "def print_windowed_data_summary(windowed_data: SubjectFramesMap):\n",
    "    \"\"\"\n",
    "    Helper function which prints some basic information on a windowed data map.\n",
    "    \n",
    "    :param windowed_data: The windowed data to summarize.\n",
    "    \"\"\"\n",
    "    print('WINDOWED DATA')\n",
    "    for key in windowed_data:\n",
    "        print(f'Subject: {key}, Windows: {len(windowed_data[key])}')\n",
    "        \n",
    "        \n",
    "def print_labelled_data_summary(labelled_data: LabelledDatasetMap):\n",
    "    \"\"\"\n",
    "    Helper function which prints basic information about the given labelled data map.\n",
    "    \n",
    "    :param labelled_data: the labelled data map to summarize.\n",
    "    \"\"\"\n",
    "    print('LABELLED DATA')\n",
    "    for key in labelled_data:\n",
    "        subject_labels = labelled_data[key][1]\n",
    "        positive_count = len(\n",
    "            list(\n",
    "                filter(lambda label: label == 1, subject_labels)\n",
    "            )\n",
    "        )\n",
    "        negative_count = len(\n",
    "            list(\n",
    "                filter(lambda label: label == 0, subject_labels)\n",
    "            )\n",
    "        )\n",
    "        print(f'Subject: {key}')\n",
    "        print(f'\\tPositive data samples: {positive_count}')\n",
    "        print(f'\\tNegative data samples: {negative_count}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T02:53:02.360348Z",
     "start_time": "2023-09-23T02:53:02.329347Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT DATA\n",
      "Number of subjects: 20\n",
      "Subject identifiers:\n",
      "S01\n",
      "S02\n",
      "S03\n",
      "S04\n",
      "S05\n",
      "S06\n",
      "S07\n",
      "S08\n",
      "S09\n",
      "S10\n",
      "S11\n",
      "S12\n",
      "S13\n",
      "S14\n",
      "S15\n",
      "S16\n",
      "S17\n",
      "S18\n",
      "S19\n",
      "S20\n",
      "SAMPLE DATAFRAME\n"
     ]
    },
    {
     "data": {
      "text/plain": "               T7           F8          Cz          P4\n13200  431.251617 -1189.493896  454.405334  345.306824\n13201  444.240265 -1194.415649  471.231140  363.666016\n13202  439.064270 -1188.719727  457.135437  325.425537\n13203  442.071136 -1193.476929  458.751099  340.463654\n13204  435.933960 -1197.149414  442.688232  333.630859",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>T7</th>\n      <th>F8</th>\n      <th>Cz</th>\n      <th>P4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>13200</th>\n      <td>431.251617</td>\n      <td>-1189.493896</td>\n      <td>454.405334</td>\n      <td>345.306824</td>\n    </tr>\n    <tr>\n      <th>13201</th>\n      <td>444.240265</td>\n      <td>-1194.415649</td>\n      <td>471.231140</td>\n      <td>363.666016</td>\n    </tr>\n    <tr>\n      <th>13202</th>\n      <td>439.064270</td>\n      <td>-1188.719727</td>\n      <td>457.135437</td>\n      <td>325.425537</td>\n    </tr>\n    <tr>\n      <th>13203</th>\n      <td>442.071136</td>\n      <td>-1193.476929</td>\n      <td>458.751099</td>\n      <td>340.463654</td>\n    </tr>\n    <tr>\n      <th>13204</th>\n      <td>435.933960</td>\n      <td>-1197.149414</td>\n      <td>442.688232</td>\n      <td>333.630859</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = retrieve_dataset()\n",
    "data_map = read_data(dataset_path)\n",
    "print_info_about_subjects(data_map)\n",
    "print('SAMPLE DATAFRAME')\n",
    "sample_dataframe = get_sample_value_from_map(data_map)\n",
    "sample_dataframe.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T02:53:02.856944200Z",
     "start_time": "2023-09-23T02:53:02.362346500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-process Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filter Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=40114\n",
      "    Range : 0 ... 40113 =      0.000 ...   200.565 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "SAMPLE FILTERED DATAFRAME\n"
     ]
    },
    {
     "data": {
      "text/plain": "       T7.Alpha       T7.Beta      T7.Theta      T7.Gamma        T7.Raw  \\\n0 -7.704948e-08  4.041212e-08 -5.873080e-08 -8.437695e-08  4.312516e+08   \n1  1.597428e+06  5.617263e+06  2.604405e+05  6.113604e+06  4.442403e+08   \n2  3.003843e+06  7.803250e+06  5.161938e+05 -2.495471e+06  4.390643e+08   \n3  4.046442e+06  5.954752e+06  7.670393e+05  1.200391e+06  4.420711e+08   \n4  4.598322e+06  2.588707e+06  1.012805e+06 -2.499456e+06  4.359340e+08   \n\n       F8.Alpha       F8.Beta      F8.Theta      F8.Gamma        F8.Raw  \\\n0  1.941780e-07 -1.985079e-07  1.718625e-07  9.059420e-08 -1.189494e+09   \n1 -7.000751e+05 -1.784533e+06 -6.256944e+05 -3.457973e+06 -1.194416e+09   \n2 -1.323957e+06 -2.837481e+06 -1.221153e+06  4.026421e+06 -1.188720e+09   \n3 -1.809801e+06 -3.154577e+06 -1.753179e+06  1.247092e+06 -1.193477e+09   \n4 -2.103975e+06 -3.215320e+06 -2.199496e+06 -9.620595e+05 -1.197149e+09   \n\n       Cz.Alpha       Cz.Beta      Cz.Theta      Cz.Gamma        Cz.Raw  \\\n0 -6.883383e-08  6.328271e-08 -7.177592e-08 -8.881784e-10  4.544053e+08   \n1  1.179360e+06  2.073403e+06  1.060481e+05  1.429068e+07  4.712311e+08   \n2  2.203946e+06  2.787055e+06  2.240760e+05 -1.378198e+06  4.571354e+08   \n3  2.936890e+06  1.816007e+06  3.662799e+05  4.587554e+04  4.587511e+08   \n4  3.276660e+06 -3.953140e+03  5.449733e+05 -1.511896e+07  4.426882e+08   \n\n       P4.Alpha       P4.Beta      P4.Theta      P4.Gamma        P4.Raw  \n0 -6.150636e-08  5.373479e-08 -4.551914e-08 -3.108624e-08  3.453068e+08  \n1  6.424138e+05 -5.416940e+06 -2.233327e+05  2.443651e+07  3.636660e+08  \n2  1.211374e+06 -7.326968e+06 -4.342064e+05 -1.151809e+07  3.254255e+08  \n3  1.644117e+06 -4.896868e+06 -6.231300e+05  1.218548e+06  3.404637e+08  \n4  1.887982e+06 -4.539841e+05 -7.769190e+05 -9.855401e+06  3.336309e+08  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>T7.Alpha</th>\n      <th>T7.Beta</th>\n      <th>T7.Theta</th>\n      <th>T7.Gamma</th>\n      <th>T7.Raw</th>\n      <th>F8.Alpha</th>\n      <th>F8.Beta</th>\n      <th>F8.Theta</th>\n      <th>F8.Gamma</th>\n      <th>F8.Raw</th>\n      <th>Cz.Alpha</th>\n      <th>Cz.Beta</th>\n      <th>Cz.Theta</th>\n      <th>Cz.Gamma</th>\n      <th>Cz.Raw</th>\n      <th>P4.Alpha</th>\n      <th>P4.Beta</th>\n      <th>P4.Theta</th>\n      <th>P4.Gamma</th>\n      <th>P4.Raw</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-7.704948e-08</td>\n      <td>4.041212e-08</td>\n      <td>-5.873080e-08</td>\n      <td>-8.437695e-08</td>\n      <td>4.312516e+08</td>\n      <td>1.941780e-07</td>\n      <td>-1.985079e-07</td>\n      <td>1.718625e-07</td>\n      <td>9.059420e-08</td>\n      <td>-1.189494e+09</td>\n      <td>-6.883383e-08</td>\n      <td>6.328271e-08</td>\n      <td>-7.177592e-08</td>\n      <td>-8.881784e-10</td>\n      <td>4.544053e+08</td>\n      <td>-6.150636e-08</td>\n      <td>5.373479e-08</td>\n      <td>-4.551914e-08</td>\n      <td>-3.108624e-08</td>\n      <td>3.453068e+08</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.597428e+06</td>\n      <td>5.617263e+06</td>\n      <td>2.604405e+05</td>\n      <td>6.113604e+06</td>\n      <td>4.442403e+08</td>\n      <td>-7.000751e+05</td>\n      <td>-1.784533e+06</td>\n      <td>-6.256944e+05</td>\n      <td>-3.457973e+06</td>\n      <td>-1.194416e+09</td>\n      <td>1.179360e+06</td>\n      <td>2.073403e+06</td>\n      <td>1.060481e+05</td>\n      <td>1.429068e+07</td>\n      <td>4.712311e+08</td>\n      <td>6.424138e+05</td>\n      <td>-5.416940e+06</td>\n      <td>-2.233327e+05</td>\n      <td>2.443651e+07</td>\n      <td>3.636660e+08</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.003843e+06</td>\n      <td>7.803250e+06</td>\n      <td>5.161938e+05</td>\n      <td>-2.495471e+06</td>\n      <td>4.390643e+08</td>\n      <td>-1.323957e+06</td>\n      <td>-2.837481e+06</td>\n      <td>-1.221153e+06</td>\n      <td>4.026421e+06</td>\n      <td>-1.188720e+09</td>\n      <td>2.203946e+06</td>\n      <td>2.787055e+06</td>\n      <td>2.240760e+05</td>\n      <td>-1.378198e+06</td>\n      <td>4.571354e+08</td>\n      <td>1.211374e+06</td>\n      <td>-7.326968e+06</td>\n      <td>-4.342064e+05</td>\n      <td>-1.151809e+07</td>\n      <td>3.254255e+08</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.046442e+06</td>\n      <td>5.954752e+06</td>\n      <td>7.670393e+05</td>\n      <td>1.200391e+06</td>\n      <td>4.420711e+08</td>\n      <td>-1.809801e+06</td>\n      <td>-3.154577e+06</td>\n      <td>-1.753179e+06</td>\n      <td>1.247092e+06</td>\n      <td>-1.193477e+09</td>\n      <td>2.936890e+06</td>\n      <td>1.816007e+06</td>\n      <td>3.662799e+05</td>\n      <td>4.587554e+04</td>\n      <td>4.587511e+08</td>\n      <td>1.644117e+06</td>\n      <td>-4.896868e+06</td>\n      <td>-6.231300e+05</td>\n      <td>1.218548e+06</td>\n      <td>3.404637e+08</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.598322e+06</td>\n      <td>2.588707e+06</td>\n      <td>1.012805e+06</td>\n      <td>-2.499456e+06</td>\n      <td>4.359340e+08</td>\n      <td>-2.103975e+06</td>\n      <td>-3.215320e+06</td>\n      <td>-2.199496e+06</td>\n      <td>-9.620595e+05</td>\n      <td>-1.197149e+09</td>\n      <td>3.276660e+06</td>\n      <td>-3.953140e+03</td>\n      <td>5.449733e+05</td>\n      <td>-1.511896e+07</td>\n      <td>4.426882e+08</td>\n      <td>1.887982e+06</td>\n      <td>-4.539841e+05</td>\n      <td>-7.769190e+05</td>\n      <td>-9.855401e+06</td>\n      <td>3.336309e+08</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_map = filter_subject_data(data_map)\n",
    "print('SAMPLE FILTERED DATAFRAME')\n",
    "sample_dataframe = get_sample_value_from_map(data_map)\n",
    "sample_dataframe.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T02:53:03.693443500Z",
     "start_time": "2023-09-23T02:53:02.857944800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Window Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINDOWED DATA\n",
      "Subject: S01, Windows: 39\n",
      "Subject: S02, Windows: 39\n",
      "Subject: S03, Windows: 39\n",
      "Subject: S04, Windows: 39\n",
      "Subject: S05, Windows: 65\n",
      "Subject: S06, Windows: 39\n",
      "Subject: S07, Windows: 39\n",
      "Subject: S08, Windows: 39\n",
      "Subject: S09, Windows: 39\n",
      "Subject: S10, Windows: 39\n",
      "Subject: S11, Windows: 39\n",
      "Subject: S12, Windows: 39\n",
      "Subject: S13, Windows: 39\n",
      "Subject: S14, Windows: 39\n",
      "Subject: S15, Windows: 39\n",
      "Subject: S16, Windows: 39\n",
      "Subject: S17, Windows: 39\n",
      "Subject: S18, Windows: 39\n",
      "Subject: S19, Windows: 39\n",
      "Subject: S20, Windows: 39\n",
      "SAMPLE WINDOW\n"
     ]
    },
    {
     "data": {
      "text/plain": "       T7.Alpha       T7.Beta      T7.Theta      T7.Gamma        T7.Raw  \\\n0 -7.704948e-08  4.041212e-08 -5.873080e-08 -8.437695e-08  4.312516e+08   \n1  1.597428e+06  5.617263e+06  2.604405e+05  6.113604e+06  4.442403e+08   \n2  3.003843e+06  7.803250e+06  5.161938e+05 -2.495471e+06  4.390643e+08   \n3  4.046442e+06  5.954752e+06  7.670393e+05  1.200391e+06  4.420711e+08   \n4  4.598322e+06  2.588707e+06  1.012805e+06 -2.499456e+06  4.359340e+08   \n\n       F8.Alpha       F8.Beta      F8.Theta      F8.Gamma        F8.Raw  \\\n0  1.941780e-07 -1.985079e-07  1.718625e-07  9.059420e-08 -1.189494e+09   \n1 -7.000751e+05 -1.784533e+06 -6.256944e+05 -3.457973e+06 -1.194416e+09   \n2 -1.323957e+06 -2.837481e+06 -1.221153e+06  4.026421e+06 -1.188720e+09   \n3 -1.809801e+06 -3.154577e+06 -1.753179e+06  1.247092e+06 -1.193477e+09   \n4 -2.103975e+06 -3.215320e+06 -2.199496e+06 -9.620595e+05 -1.197149e+09   \n\n       Cz.Alpha       Cz.Beta      Cz.Theta      Cz.Gamma        Cz.Raw  \\\n0 -6.883383e-08  6.328271e-08 -7.177592e-08 -8.881784e-10  4.544053e+08   \n1  1.179360e+06  2.073403e+06  1.060481e+05  1.429068e+07  4.712311e+08   \n2  2.203946e+06  2.787055e+06  2.240760e+05 -1.378198e+06  4.571354e+08   \n3  2.936890e+06  1.816007e+06  3.662799e+05  4.587554e+04  4.587511e+08   \n4  3.276660e+06 -3.953140e+03  5.449733e+05 -1.511896e+07  4.426882e+08   \n\n       P4.Alpha       P4.Beta      P4.Theta      P4.Gamma        P4.Raw  \n0 -6.150636e-08  5.373479e-08 -4.551914e-08 -3.108624e-08  3.453068e+08  \n1  6.424138e+05 -5.416940e+06 -2.233327e+05  2.443651e+07  3.636660e+08  \n2  1.211374e+06 -7.326968e+06 -4.342064e+05 -1.151809e+07  3.254255e+08  \n3  1.644117e+06 -4.896868e+06 -6.231300e+05  1.218548e+06  3.404637e+08  \n4  1.887982e+06 -4.539841e+05 -7.769190e+05 -9.855401e+06  3.336309e+08  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>T7.Alpha</th>\n      <th>T7.Beta</th>\n      <th>T7.Theta</th>\n      <th>T7.Gamma</th>\n      <th>T7.Raw</th>\n      <th>F8.Alpha</th>\n      <th>F8.Beta</th>\n      <th>F8.Theta</th>\n      <th>F8.Gamma</th>\n      <th>F8.Raw</th>\n      <th>Cz.Alpha</th>\n      <th>Cz.Beta</th>\n      <th>Cz.Theta</th>\n      <th>Cz.Gamma</th>\n      <th>Cz.Raw</th>\n      <th>P4.Alpha</th>\n      <th>P4.Beta</th>\n      <th>P4.Theta</th>\n      <th>P4.Gamma</th>\n      <th>P4.Raw</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-7.704948e-08</td>\n      <td>4.041212e-08</td>\n      <td>-5.873080e-08</td>\n      <td>-8.437695e-08</td>\n      <td>4.312516e+08</td>\n      <td>1.941780e-07</td>\n      <td>-1.985079e-07</td>\n      <td>1.718625e-07</td>\n      <td>9.059420e-08</td>\n      <td>-1.189494e+09</td>\n      <td>-6.883383e-08</td>\n      <td>6.328271e-08</td>\n      <td>-7.177592e-08</td>\n      <td>-8.881784e-10</td>\n      <td>4.544053e+08</td>\n      <td>-6.150636e-08</td>\n      <td>5.373479e-08</td>\n      <td>-4.551914e-08</td>\n      <td>-3.108624e-08</td>\n      <td>3.453068e+08</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.597428e+06</td>\n      <td>5.617263e+06</td>\n      <td>2.604405e+05</td>\n      <td>6.113604e+06</td>\n      <td>4.442403e+08</td>\n      <td>-7.000751e+05</td>\n      <td>-1.784533e+06</td>\n      <td>-6.256944e+05</td>\n      <td>-3.457973e+06</td>\n      <td>-1.194416e+09</td>\n      <td>1.179360e+06</td>\n      <td>2.073403e+06</td>\n      <td>1.060481e+05</td>\n      <td>1.429068e+07</td>\n      <td>4.712311e+08</td>\n      <td>6.424138e+05</td>\n      <td>-5.416940e+06</td>\n      <td>-2.233327e+05</td>\n      <td>2.443651e+07</td>\n      <td>3.636660e+08</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.003843e+06</td>\n      <td>7.803250e+06</td>\n      <td>5.161938e+05</td>\n      <td>-2.495471e+06</td>\n      <td>4.390643e+08</td>\n      <td>-1.323957e+06</td>\n      <td>-2.837481e+06</td>\n      <td>-1.221153e+06</td>\n      <td>4.026421e+06</td>\n      <td>-1.188720e+09</td>\n      <td>2.203946e+06</td>\n      <td>2.787055e+06</td>\n      <td>2.240760e+05</td>\n      <td>-1.378198e+06</td>\n      <td>4.571354e+08</td>\n      <td>1.211374e+06</td>\n      <td>-7.326968e+06</td>\n      <td>-4.342064e+05</td>\n      <td>-1.151809e+07</td>\n      <td>3.254255e+08</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.046442e+06</td>\n      <td>5.954752e+06</td>\n      <td>7.670393e+05</td>\n      <td>1.200391e+06</td>\n      <td>4.420711e+08</td>\n      <td>-1.809801e+06</td>\n      <td>-3.154577e+06</td>\n      <td>-1.753179e+06</td>\n      <td>1.247092e+06</td>\n      <td>-1.193477e+09</td>\n      <td>2.936890e+06</td>\n      <td>1.816007e+06</td>\n      <td>3.662799e+05</td>\n      <td>4.587554e+04</td>\n      <td>4.587511e+08</td>\n      <td>1.644117e+06</td>\n      <td>-4.896868e+06</td>\n      <td>-6.231300e+05</td>\n      <td>1.218548e+06</td>\n      <td>3.404637e+08</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.598322e+06</td>\n      <td>2.588707e+06</td>\n      <td>1.012805e+06</td>\n      <td>-2.499456e+06</td>\n      <td>4.359340e+08</td>\n      <td>-2.103975e+06</td>\n      <td>-3.215320e+06</td>\n      <td>-2.199496e+06</td>\n      <td>-9.620595e+05</td>\n      <td>-1.197149e+09</td>\n      <td>3.276660e+06</td>\n      <td>-3.953140e+03</td>\n      <td>5.449733e+05</td>\n      <td>-1.511896e+07</td>\n      <td>4.426882e+08</td>\n      <td>1.887982e+06</td>\n      <td>-4.539841e+05</td>\n      <td>-7.769190e+05</td>\n      <td>-9.855401e+06</td>\n      <td>3.336309e+08</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_map = window_dataset(data_map)\n",
    "print_windowed_data_summary(data_map)\n",
    "print('SAMPLE WINDOW')\n",
    "sample_windows = get_sample_value_from_map(data_map)\n",
    "sample_windows[0].head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T02:53:03.753944100Z",
     "start_time": "2023-09-23T02:53:03.693943500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Extraction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE FEATURES\n",
      "Size: 80\n",
      "Elements: [-1.38215250e+07  1.39524481e+07  2.30669831e+04  1.04166667e-01\n",
      " -1.33188938e+07  1.23118873e+07  1.07595349e+04  2.13333333e-01\n",
      " -8.50688623e+06  7.58143167e+06  5.38479622e+03  6.33333333e-02\n",
      " -3.11927915e+07  3.15010114e+07  3.08707558e+03  5.43333333e-01\n",
      "  3.86584106e+08  4.81055847e+08  4.40934159e+08  0.00000000e+00\n",
      " -1.63194953e+07  1.54157468e+07 -1.19110791e+04  1.05000000e-01\n",
      " -1.22098452e+07  1.36056335e+07  9.85539811e+02  2.15833333e-01\n",
      " -1.09752728e+07  9.74591110e+06 -1.56998768e+04  6.33333333e-02\n",
      " -3.36370308e+07  2.89119063e+07 -3.10105768e+03  5.55833333e-01\n",
      " -1.23803223e+09 -1.14405408e+09 -1.19490520e+09  0.00000000e+00\n",
      " -1.44408963e+07  1.33289983e+07  2.09954706e+04  1.02500000e-01\n",
      " -1.29073672e+07  9.43481925e+06 -5.55832882e+03  2.05000000e-01\n",
      " -6.66783987e+06  6.50344327e+06 -5.37477503e+03  6.16666667e-02\n",
      " -1.91941124e+07  2.21471060e+07  8.34716262e+03  5.11666667e-01\n",
      "  4.01601685e+08  4.87976532e+08  4.54110164e+08  0.00000000e+00\n",
      " -1.18245790e+07  1.21818234e+07  3.44565545e+03  1.04166667e-01\n",
      " -9.40076116e+06  9.40781688e+06 -6.08003201e+03  2.21666667e-01\n",
      " -4.27661239e+06  5.24822742e+06 -1.49562519e+04  6.33333333e-02\n",
      " -1.85122410e+07  2.44365142e+07  1.14925118e+04  6.57500000e-01\n",
      "  3.03505981e+08  3.69275848e+08  3.41547010e+08  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "data_map = extract_features(data_map)\n",
    "sample_windows = get_sample_value_from_map(data_map)\n",
    "sample_frame = sample_windows[0]\n",
    "print('SAMPLE FEATURES')\n",
    "print(f'Size: {len(sample_frame)}')\n",
    "print(f'Elements: {sample_frame}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T02:53:06.080943700Z",
     "start_time": "2023-09-23T02:53:03.724443500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare Training and Testing Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Label Datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABELLED DATA\n",
      "Subject: S01\n",
      "\tPositive data samples: 39\n",
      "\tNegative data samples: 767\n",
      "Subject: S02\n",
      "\tPositive data samples: 39\n",
      "\tNegative data samples: 767\n",
      "Subject: S03\n",
      "\tPositive data samples: 39\n",
      "\tNegative data samples: 767\n",
      "Subject: S04\n",
      "\tPositive data samples: 39\n",
      "\tNegative data samples: 767\n",
      "Subject: S05\n",
      "\tPositive data samples: 65\n",
      "\tNegative data samples: 741\n",
      "Subject: S06\n",
      "\tPositive data samples: 39\n",
      "\tNegative data samples: 767\n",
      "Subject: S07\n",
      "\tPositive data samples: 39\n",
      "\tNegative data samples: 767\n",
      "Subject: S08\n",
      "\tPositive data samples: 39\n",
      "\tNegative data samples: 767\n",
      "Subject: S09\n",
      "\tPositive data samples: 39\n",
      "\tNegative data samples: 767\n",
      "Subject: S10\n",
      "\tPositive data samples: 39\n",
      "\tNegative data samples: 767\n",
      "Subject: S11\n",
      "\tPositive data samples: 39\n",
      "\tNegative data samples: 767\n",
      "Subject: S12\n",
      "\tPositive data samples: 39\n",
      "\tNegative data samples: 767\n",
      "Subject: S13\n",
      "\tPositive data samples: 39\n",
      "\tNegative data samples: 767\n",
      "Subject: S14\n",
      "\tPositive data samples: 39\n",
      "\tNegative data samples: 767\n",
      "Subject: S15\n",
      "\tPositive data samples: 39\n",
      "\tNegative data samples: 767\n",
      "Subject: S16\n",
      "\tPositive data samples: 39\n",
      "\tNegative data samples: 767\n",
      "Subject: S17\n",
      "\tPositive data samples: 39\n",
      "\tNegative data samples: 767\n",
      "Subject: S18\n",
      "\tPositive data samples: 39\n",
      "\tNegative data samples: 767\n",
      "Subject: S19\n",
      "\tPositive data samples: 39\n",
      "\tNegative data samples: 767\n",
      "Subject: S20\n",
      "\tPositive data samples: 39\n",
      "\tNegative data samples: 767\n"
     ]
    }
   ],
   "source": [
    "data_map = get_labelled_dataset_map(data_map)\n",
    "print_labelled_data_summary(data_map)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T02:53:06.140444200Z",
     "start_time": "2023-09-23T02:53:06.080943700Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
