{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e87529cbb033c6e0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9334d3cf4e5ce17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:24:54.344895Z",
     "start_time": "2024-05-11T00:24:43.301623Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dataclasses\n",
    "import enum\n",
    "import typing\n",
    "import random\n",
    "import time\n",
    "import statistics\n",
    "import fuzzy_hash_lib\n",
    "import feature_encoding.base\n",
    "import feature_encoding.threshold\n",
    "\n",
    "from eeg_auth_models_framework import data, pre_process, features, processor, normalization\n",
    "from eeg_auth_models_framework.utils import conversion\n",
    "from auth_biohash import orthonormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c078babbe01fd2e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74fc12d929fbaf80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:24:54.360396Z",
     "start_time": "2024-05-11T00:24:54.346395Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AUTHENTICATION_THRESHOLDS = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "DATASET_SAMPLE_FREQ_HZ = 200\n",
    "DATA_CHANNEL_NAMES = ['T7','F8','Cz','P4']\n",
    "FREQUENCIES = [\n",
    "    pre_process.FrequencyBand(lower=8.0, upper=12.0, label='Alpha'),\n",
    "    pre_process.FrequencyBand(lower=12.0, upper=35.0, label='Beta'),\n",
    "    pre_process.FrequencyBand(lower=4.0, upper=8.0, label='Theta'),\n",
    "    pre_process.FrequencyBand(lower=35.0, upper=None, label='Gamma'),\n",
    "    pre_process.FrequencyBand(lower=None, upper=None, label='Raw'),\n",
    "]\n",
    "WINDOW_SIZE = 1200\n",
    "WINDOW_OVERLAP = 0\n",
    "BINARY_THRESHOLD = 127\n",
    "RESCALE_LOWER = 0\n",
    "RESCALE_UPPER = 255\n",
    "RANDOM_SEED = 100000000000\n",
    "RANDOM_GENERATOR = random.Random(RANDOM_SEED)\n",
    "SYSTEMIC_SAMPLE_RATE = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b01453c4b82d01",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d77afdaf2e375e98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:24:54.375898Z",
     "start_time": "2024-05-11T00:24:54.361395Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TestResultType(enum.Enum):\n",
    "    TRUE_POSITIVE = enum.auto()\n",
    "    FALSE_POSITIVE = enum.auto()\n",
    "    FALSE_NEGATIVE = enum.auto()\n",
    "    TRUE_NEGATIVE = enum.auto()\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class TestResultsSummary:\n",
    "    true_positives: int = 0\n",
    "    false_positives: int = 0\n",
    "    false_negatives: int = 0\n",
    "    true_negatives: int = 0\n",
    "    \n",
    "    @classmethod\n",
    "    def merge_summaries(cls, \n",
    "                        summary_a: 'TestResultsSummary', \n",
    "                        summary_b: 'TestResultsSummary') -> 'TestResultsSummary':\n",
    "        return TestResultsSummary(\n",
    "            true_positives=summary_a.true_positives + summary_b.true_positives,\n",
    "            false_positives=summary_a.false_positives + summary_b.false_positives,\n",
    "            false_negatives=summary_a.false_negatives + summary_b.false_negatives,\n",
    "            true_negatives=summary_a.true_negatives + summary_b.true_negatives\n",
    "        )\n",
    "    \n",
    "    def increment_count(self, result_type: TestResultType):\n",
    "        if result_type == TestResultType.TRUE_POSITIVE:\n",
    "            self.true_positives += 1\n",
    "        elif result_type == TestResultType.FALSE_POSITIVE:\n",
    "            self.false_positives += 1\n",
    "        elif result_type == TestResultType.FALSE_NEGATIVE:\n",
    "            self.false_negatives += 1\n",
    "        else:\n",
    "            self.true_negatives += 1\n",
    "    \n",
    "    @property\n",
    "    def accuracy(self) -> float:\n",
    "        hits = self.true_positives + self.true_negatives\n",
    "        total = (\n",
    "            self.true_positives + self.true_negatives + \n",
    "            self.false_positives + self.false_negatives\n",
    "        )\n",
    "        return hits / total\n",
    "\n",
    "    @property\n",
    "    def false_accept_rate(self) -> float:\n",
    "        return self.false_positives / (self.false_positives + self.true_negatives)\n",
    "    \n",
    "    @property\n",
    "    def false_reject_rate(self):\n",
    "        return self.false_negatives / (self.false_negatives + self.true_positives)\n",
    "    \n",
    "    @property\n",
    "    def half_total_error_rate(self) -> float:\n",
    "        return (self.false_accept_rate + self.false_reject_rate) / 2\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class HashTest:\n",
    "    expected_result: bool\n",
    "    threshold: int\n",
    "    if_expected: TestResultType\n",
    "    if_unexpected: TestResultType\n",
    "    hashes: typing.Tuple[fuzzy_hash_lib.FuzzyHash, fuzzy_hash_lib.FuzzyHash]\n",
    "    \n",
    "    def run_test(self):\n",
    "        similarity = fuzzy_hash_lib.FuzzyHash.compare(self.hashes[0], self.hashes[1])\n",
    "        is_match = similarity >= self.threshold\n",
    "        if is_match != self.expected_result:\n",
    "            return self.if_unexpected\n",
    "        return self.if_expected\n",
    "    \n",
    "@dataclasses.dataclass\n",
    "class ThresholdTestSet:\n",
    "    threshold: int\n",
    "    template_hash: fuzzy_hash_lib.FuzzyHash\n",
    "    positive_cases: typing.List[fuzzy_hash_lib.FuzzyHash]\n",
    "    negative_cases: typing.List[fuzzy_hash_lib.FuzzyHash]\n",
    "    \n",
    "@dataclasses.dataclass\n",
    "class SubjectTestSet:\n",
    "    subject_id: str\n",
    "    threshold_tests: typing.List[ThresholdTestSet]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4a1eacf6e16f5a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75bfbf6579124b68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:24:54.391395Z",
     "start_time": "2024-05-11T00:24:54.377896Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "downloader = data.AuditoryDataDownloader()\n",
    "reader = data.AuditoryDataReader()\n",
    "converter = conversion.MNEDataFrameConverter(\n",
    "    channels=DATA_CHANNEL_NAMES, \n",
    "    sample_frequency=DATASET_SAMPLE_FREQ_HZ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0f0fd7d636944e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Processing Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b7186e3249193c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Template Hash Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ee06c4e477a5a4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Pre-Processing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d3db3bb9c8b689c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:24:54.406896Z",
     "start_time": "2024-05-11T00:24:54.393396Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "template_pre_process_steps = pre_process.PreProcessingPipeline([\n",
    "    pre_process.EEGBandpassFilterStep(\n",
    "        FREQUENCIES,\n",
    "        converter\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea5c276c742bb8e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Feature Extraction Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5ef89540e783a6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:24:54.422394Z",
     "start_time": "2024-05-11T00:24:54.408396Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "template_feature_extraction_steps = features.FeatureExtractPipeline([\n",
    "    features.StatisticalFeatureExtractor([\n",
    "        features.StatisticalFeature.MIN,\n",
    "        features.StatisticalFeature.MAX,\n",
    "        features.StatisticalFeature.MEAN,\n",
    "        features.StatisticalFeature.ZERO_CROSSING_RATE\n",
    "    ])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e41ff9f4766b9e9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Normalization Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd430d300289bb7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:24:54.437894Z",
     "start_time": "2024-05-11T00:24:54.423898Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "template_normalization_steps = normalization.NormalizationPipeline([\n",
    "    normalization.RescaleNormalizationStep(RESCALE_LOWER, RESCALE_UPPER),\n",
    "    normalization.HistogramEqualizationStep(RESCALE_LOWER, RESCALE_UPPER)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0856751c508f732",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data Processor Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b4049bbc6bb64e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:24:54.453394Z",
     "start_time": "2024-05-11T00:24:54.439396Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "template_data_processor = processor.DataProcessor(\n",
    "    pre_process=template_pre_process_steps,\n",
    "    feature_extraction=template_feature_extraction_steps,\n",
    "    normalization=template_normalization_steps\n",
    ")\n",
    "token_template_processor = processor.DataProcessor(\n",
    "    pre_process=template_pre_process_steps,\n",
    "    feature_extraction=template_feature_extraction_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4dd223e88e171a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Sample Data Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab9a2c1c60e36ae",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Pre-Processing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb1546861f56509e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:24:54.468894Z",
     "start_time": "2024-05-11T00:24:54.454895Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_process_steps = pre_process.PreProcessingPipeline([\n",
    "    pre_process.EEGBandpassFilterStep(\n",
    "        FREQUENCIES,\n",
    "        converter\n",
    "    ),\n",
    "    pre_process.DataWindowStep(WINDOW_SIZE, WINDOW_OVERLAP)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bf70ac66cb428e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Feature Extraction Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f7d923c4c079c73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:24:54.484394Z",
     "start_time": "2024-05-11T00:24:54.471896Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_extraction_steps = features.FeatureExtractPipeline([\n",
    "    features.StatisticalFeatureExtractor([\n",
    "        features.StatisticalFeature.MIN,\n",
    "        features.StatisticalFeature.MAX,\n",
    "        features.StatisticalFeature.MEAN,\n",
    "        features.StatisticalFeature.ZERO_CROSSING_RATE\n",
    "    ])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8cd3ca3a0d9dfd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Normalization Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dca47d264b318934",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:24:54.499896Z",
     "start_time": "2024-05-11T00:24:54.485395Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalization_steps = normalization.NormalizationPipeline([\n",
    "    normalization.RescaleNormalizationStep(RESCALE_LOWER, RESCALE_UPPER),\n",
    "    normalization.HistogramEqualizationStep(RESCALE_LOWER, RESCALE_UPPER)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e75d73ab1e1f8e8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data Processor Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c41639bc78597bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:24:54.515395Z",
     "start_time": "2024-05-11T00:24:54.501395Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_processor = processor.DataProcessor(\n",
    "    pre_process=pre_process_steps,\n",
    "    feature_extraction=feature_extraction_steps,\n",
    "    normalization=normalization_steps\n",
    ")\n",
    "token_processor = processor.DataProcessor(\n",
    "    pre_process=pre_process_steps,\n",
    "    feature_extraction=feature_extraction_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cedb17c2a956396",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Subject Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "927706e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RawDataMap = typing.Dict[str, typing.List[pd.DataFrame]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e51b5330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_test_maps(data_map: RawDataMap) -> typing.Tuple[RawDataMap, RawDataMap]:\n",
    "    result_training = {}\n",
    "    result_test = {}\n",
    "\n",
    "    for subject in data_map:\n",
    "        result_training[subject] = []\n",
    "        result_test[subject] = []\n",
    "        for frame_data in data_map[subject]:\n",
    "            training_frame, test_frame = make_training_test_frames(frame_data)\n",
    "            result_training[subject].append(training_frame)\n",
    "            result_test[subject].append(test_frame)\n",
    "\n",
    "    return result_training, result_test\n",
    "\n",
    "\n",
    "def make_training_test_frames(frame: pd.DataFrame) -> typing.Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    training = frame[::SYSTEMIC_SAMPLE_RATE]\n",
    "    test = frame.drop(training.index)\n",
    "    return training, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7797f267c21560a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:24:55.057142Z",
     "start_time": "2024-05-11T00:24:54.516896Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = downloader.retrieve()\n",
    "subject_data_map = reader.format_data(data_path)\n",
    "subject_data_train, subject_data_test = make_training_test_maps(subject_data_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9ccaf392073b2",
   "metadata": {},
   "source": [
    "## Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bf944af53ffa6791",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:24:55.072643Z",
     "start_time": "2024-05-11T00:24:55.058144Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens_map = {subject: orthonormalization.TokenDataGenerator.generate_random_token() for subject in subject_data_map}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05e630093ab2c05",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922b8afcbceadfb8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Template Hash Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb45b4e3dfc73b71",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c55ac43b7e3bd3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:24:57.180642Z",
     "start_time": "2024-05-11T00:24:55.073643Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=13372\n",
      "    Range : 0 ... 13371 =      0.000 ...    66.855 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=13372\n",
      "    Range : 0 ... 13371 =      0.000 ...    66.855 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "template_data_map = {\n",
    "    subject: template_data_processor.process(subject_data_train[subject]) \n",
    "    for subject in subject_data_train\n",
    "}\n",
    "token_template_data_map = {\n",
    "    subject: token_template_processor.process(subject_data_train[subject]) \n",
    "    for subject in subject_data_train\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc28955aaed5138",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e6434d226cf753d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:24:57.196142Z",
     "start_time": "2024-05-11T00:24:57.181643Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SubjectTemplatePair = typing.Tuple[str, fuzzy_hash_lib.FuzzyHash]\n",
    "SubjectProcessedData = typing.Dict[str, typing.List[np.ndarray]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a2b982db6a2fadd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:24:57.211642Z",
     "start_time": "2024-05-11T00:24:57.197144Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hash_vectors(vectors_to_hash: typing.List[np.ndarray], \n",
    "                 encoder: feature_encoding.base.BinaryEncoder,\n",
    "                 token: str = None) -> typing.List[fuzzy_hash_lib.FuzzyHash]:\n",
    "    normalized_vectors = vectors_to_hash\n",
    "    token_data_generator = orthonormalization.TokenDataGenerator(token)\n",
    "    normalizer = orthonormalization.TokenMatrixNormalization(token_data_generator)\n",
    "    if token is not None:\n",
    "        normalized_vectors = [normalizer.normalize(v) for v in normalized_vectors]\n",
    "    binary_vectors = [encoder.encode(v) for v in normalized_vectors]\n",
    "    return [fuzzy_hash_lib.FuzzyHash.from_text(bv) for bv in binary_vectors]\n",
    "\n",
    "\n",
    "def iter_template_hashes(template_data: SubjectProcessedData, \n",
    "                         encoder: feature_encoding.base.BinaryEncoder,\n",
    "                         tokens: typing.Dict[str, str] = None) -> typing.Iterator[SubjectTemplatePair]:\n",
    "    for subject in template_data:\n",
    "        token = tokens.get(subject) if tokens is not None else None\n",
    "        hashes_list = hash_vectors(template_data[subject], encoder, token)\n",
    "        if len(hashes_list) != 1:\n",
    "            print(\n",
    "                f'[warning] There should be only one template hash per subject, '\n",
    "                f'but subject {subject} has {len(hashes_list)} template hashes'\n",
    "            )\n",
    "            continue\n",
    "        yield subject, hashes_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c3b5b30b09100",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Sample Hashes Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61922cf3aa69029f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Subject Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14571cab6a6e2b3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:25:02.326642Z",
     "start_time": "2024-05-11T00:24:57.213145Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=26742\n",
      "    Range : 0 ... 26741 =      0.000 ...   133.705 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=26742\n",
      "    Range : 0 ... 26741 =      0.000 ...   133.705 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "processed_data_map = {\n",
    "    subject: data_processor.process(subject_data_test[subject])\n",
    "    for subject in subject_data_test\n",
    "}\n",
    "token_processed_data_map = {\n",
    "    subject: token_processor.process(subject_data_test[subject])\n",
    "    for subject in subject_data_test\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a288831ff9f35c2a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b238964a0fbfffbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:25:02.342142Z",
     "start_time": "2024-05-11T00:25:02.328142Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SubjectSamplesPair = typing.Tuple[str, typing.List[fuzzy_hash_lib.FuzzyHash]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "db0180b3ef2eeb0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:25:02.357644Z",
     "start_time": "2024-05-11T00:25:02.343144Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def iter_sample_hashes(data_map: SubjectProcessedData, \n",
    "                       encoder: feature_encoding.base.BinaryEncoder,\n",
    "                       tokens: typing.Dict[str, str] = None) -> typing.Iterator[SubjectSamplesPair]:\n",
    "    for subject in data_map:\n",
    "        token = tokens.get(subject) if tokens is not None else None\n",
    "        vectors = hash_vectors(data_map[subject], encoder, token)\n",
    "        yield subject, vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b07aa6f74300e14",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Test Set Assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2360b694971281a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Gathering Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fd39807ddd3d9d41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:25:02.373143Z",
     "start_time": "2024-05-11T00:25:02.359144Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def iter_subject_test_sets(template_data: SubjectProcessedData, \n",
    "                           sample_data: SubjectProcessedData, \n",
    "                           encoder: feature_encoding.base.BinaryEncoder,\n",
    "                           tokens: typing.Dict[str, str] = None) -> typing.Iterator[SubjectTestSet]:\n",
    "    for target_subject, template_hash in iter_template_hashes(template_data, encoder, tokens):\n",
    "        threshold_tests = []\n",
    "        for threshold in AUTHENTICATION_THRESHOLDS:\n",
    "            threshold_test_set = ThresholdTestSet(\n",
    "                positive_cases=[], negative_cases=[], \n",
    "                template_hash=template_hash, threshold=threshold\n",
    "            )\n",
    "            for subject, hashes in iter_sample_hashes(sample_data, encoder, tokens):\n",
    "                if subject == target_subject:\n",
    "                    threshold_test_set.positive_cases.extend(hashes)\n",
    "                else:\n",
    "                    threshold_test_set.negative_cases.extend(hashes)\n",
    "            threshold_tests.append(threshold_test_set)\n",
    "        yield SubjectTestSet(\n",
    "            subject_id=target_subject,\n",
    "            threshold_tests=threshold_tests\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c688683e63476bca",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generating Hash Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7bd675d75ce04fc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:25:02.388643Z",
     "start_time": "2024-05-11T00:25:02.374645Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ThresholdTestsPair = typing.Tuple[str, typing.List[HashTest]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cb9c52ad46dd1b9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:25:02.404144Z",
     "start_time": "2024-05-11T00:25:02.391643Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_hash_tests(test_set: ThresholdTestSet) -> typing.List[HashTest]:\n",
    "    tests = []\n",
    "    sample_size = min(len(test_set.positive_cases), len(test_set.negative_cases))\n",
    "    should_match_cases: typing.List[fuzzy_hash_lib.FuzzyHash] = RANDOM_GENERATOR.sample(test_set.positive_cases, sample_size)\n",
    "    should_not_match_cases: typing.List[fuzzy_hash_lib.FuzzyHash] = RANDOM_GENERATOR.sample(test_set.negative_cases, sample_size)\n",
    "    for sample in should_match_cases:\n",
    "        tests.append(\n",
    "            HashTest(\n",
    "                expected_result=True, \n",
    "                threshold=test_set.threshold, \n",
    "                hashes=(test_set.template_hash, sample),\n",
    "                if_expected=TestResultType.TRUE_POSITIVE,\n",
    "                if_unexpected=TestResultType.FALSE_NEGATIVE\n",
    "            )\n",
    "        )\n",
    "    for sample in should_not_match_cases:\n",
    "        tests.append(\n",
    "            HashTest(\n",
    "                expected_result=False, \n",
    "                threshold=test_set.threshold, \n",
    "                hashes=(test_set.template_hash, sample),\n",
    "                if_expected=TestResultType.TRUE_NEGATIVE,\n",
    "                if_unexpected=TestResultType.FALSE_POSITIVE\n",
    "            )\n",
    "        )\n",
    "    return tests\n",
    "\n",
    "\n",
    "def iter_hash_tests(template_data: SubjectProcessedData, \n",
    "                    sample_data: SubjectProcessedData, \n",
    "                    encoder: feature_encoding.base.BinaryEncoder,\n",
    "                    tokens: typing.Dict[str, str] = None) -> ThresholdTestsPair:\n",
    "    for subject_test_set in iter_subject_test_sets(template_data, sample_data, encoder, tokens):\n",
    "        for threshold_test_data in subject_test_set.threshold_tests:\n",
    "            yield threshold_test_data.threshold, make_hash_tests(threshold_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f687ed4b216d82",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Execute Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e077206a6e179ebc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:25:02.419643Z",
     "start_time": "2024-05-11T00:25:02.405643Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_hash_tests(hash_tests: typing.List[HashTest]) -> TestResultsSummary:\n",
    "    summary = TestResultsSummary()\n",
    "    for test in hash_tests:\n",
    "        result_type = test.run_test()\n",
    "        summary.increment_count(result_type)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baea3deb6d612c88",
   "metadata": {},
   "source": [
    "## No Tokens with Histogram Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3dd953ac30d82d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:25:16.060142Z",
     "start_time": "2024-05-11T00:25:02.421142Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_token_results = {}\n",
    "threshold_encoder = feature_encoding.threshold.ThresholdBinaryEncoder(BINARY_THRESHOLD)\n",
    "no_token_args = (\n",
    "    template_data_map, processed_data_map, threshold_encoder\n",
    ")\n",
    "for threshold_type, hash_test_data in iter_hash_tests(*no_token_args):\n",
    "    if threshold_type not in no_token_results:\n",
    "        no_token_results[threshold_type] = TestResultsSummary()\n",
    "    no_token_results[threshold_type] = TestResultsSummary.merge_summaries(\n",
    "        no_token_results[threshold_type],\n",
    "        run_hash_tests(hash_test_data)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "195e97184d2409c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:25:16.137642Z",
     "start_time": "2024-05-11T00:25:16.061144Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>FAR</th>\n",
       "      <th>FRR</th>\n",
       "      <th>HTER</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.052045</td>\n",
       "      <td>0.241636</td>\n",
       "      <td>0.146840</td>\n",
       "      <td>0.853160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.055762</td>\n",
       "      <td>0.241636</td>\n",
       "      <td>0.148699</td>\n",
       "      <td>0.851301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304833</td>\n",
       "      <td>0.152416</td>\n",
       "      <td>0.847584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304833</td>\n",
       "      <td>0.152416</td>\n",
       "      <td>0.847584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.301115</td>\n",
       "      <td>0.152416</td>\n",
       "      <td>0.847584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.304833</td>\n",
       "      <td>0.154275</td>\n",
       "      <td>0.845725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.304833</td>\n",
       "      <td>0.154275</td>\n",
       "      <td>0.845725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.304833</td>\n",
       "      <td>0.156134</td>\n",
       "      <td>0.843866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.304833</td>\n",
       "      <td>0.156134</td>\n",
       "      <td>0.843866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold       FAR       FRR      HTER  Accuracy\n",
       "1         20  0.052045  0.241636  0.146840  0.853160\n",
       "0         10  0.055762  0.241636  0.148699  0.851301\n",
       "5         60  0.000000  0.304833  0.152416  0.847584\n",
       "6         70  0.000000  0.304833  0.152416  0.847584\n",
       "2         30  0.003717  0.301115  0.152416  0.847584\n",
       "3         40  0.003717  0.304833  0.154275  0.845725\n",
       "4         50  0.003717  0.304833  0.154275  0.845725\n",
       "7         80  0.007435  0.304833  0.156134  0.843866\n",
       "8         90  0.007435  0.304833  0.156134  0.843866"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_token_data = []\n",
    "for threshold_type, result_summary in no_token_results.items():\n",
    "    no_token_data.append([\n",
    "        threshold_type, result_summary.false_accept_rate, \n",
    "        result_summary.false_reject_rate, result_summary.half_total_error_rate, \n",
    "        result_summary.accuracy\n",
    "    ])\n",
    "no_token_df = pd.DataFrame(no_token_data, columns=['Threshold', 'FAR', 'FRR', 'HTER', 'Accuracy'])\n",
    "no_token_df.sort_values(by='HTER', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec341bb21ce3cc0",
   "metadata": {},
   "source": [
    "## Tokens without Histogram Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eca0fd180ff799a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:30:06.246913Z",
     "start_time": "2024-05-11T00:25:16.139143Z"
    }
   },
   "outputs": [],
   "source": [
    "token_results = {}\n",
    "token_args = (\n",
    "    token_template_data_map, token_processed_data_map, threshold_encoder, tokens_map\n",
    ")\n",
    "for threshold_type, hash_test_data in iter_hash_tests(*token_args):\n",
    "    if threshold_type not in token_results:\n",
    "        token_results[threshold_type] = TestResultsSummary()\n",
    "    token_results[threshold_type] = TestResultsSummary.merge_summaries(\n",
    "        token_results[threshold_type],\n",
    "        run_hash_tests(hash_test_data)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2e0a3bcc16deb964",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:30:06.262413Z",
     "start_time": "2024-05-11T00:30:06.249415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>FAR</th>\n",
       "      <th>FRR</th>\n",
       "      <th>HTER</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.635688</td>\n",
       "      <td>0.317844</td>\n",
       "      <td>0.682156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.635688</td>\n",
       "      <td>0.317844</td>\n",
       "      <td>0.682156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.840149</td>\n",
       "      <td>0.420074</td>\n",
       "      <td>0.579926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.940520</td>\n",
       "      <td>0.470260</td>\n",
       "      <td>0.529740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.940520</td>\n",
       "      <td>0.470260</td>\n",
       "      <td>0.529740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.940520</td>\n",
       "      <td>0.470260</td>\n",
       "      <td>0.529740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.940520</td>\n",
       "      <td>0.470260</td>\n",
       "      <td>0.529740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.940520</td>\n",
       "      <td>0.470260</td>\n",
       "      <td>0.529740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.940520</td>\n",
       "      <td>0.470260</td>\n",
       "      <td>0.529740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold  FAR       FRR      HTER  Accuracy\n",
       "0         10  0.0  0.635688  0.317844  0.682156\n",
       "1         20  0.0  0.635688  0.317844  0.682156\n",
       "2         30  0.0  0.840149  0.420074  0.579926\n",
       "3         40  0.0  0.940520  0.470260  0.529740\n",
       "4         50  0.0  0.940520  0.470260  0.529740\n",
       "5         60  0.0  0.940520  0.470260  0.529740\n",
       "6         70  0.0  0.940520  0.470260  0.529740\n",
       "7         80  0.0  0.940520  0.470260  0.529740\n",
       "8         90  0.0  0.940520  0.470260  0.529740"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_data = []\n",
    "for threshold_type, result_summary in token_results.items():\n",
    "    token_data.append([\n",
    "        threshold_type, result_summary.false_accept_rate, \n",
    "        result_summary.false_reject_rate, result_summary.half_total_error_rate, \n",
    "        result_summary.accuracy\n",
    "    ])\n",
    "token_df = pd.DataFrame(token_data, columns=['Threshold', 'FAR', 'FRR', 'HTER', 'Accuracy'])\n",
    "token_df.sort_values(by='HTER', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34c6d4fbf6427e7",
   "metadata": {},
   "source": [
    "## Tokens with Histogram Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d697cd8677ab2af6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:34:41.177663Z",
     "start_time": "2024-05-11T00:30:06.263417Z"
    }
   },
   "outputs": [],
   "source": [
    "token_norm_results = {}\n",
    "token_norm_args = (\n",
    "    template_data_map, processed_data_map, threshold_encoder, tokens_map\n",
    ")\n",
    "for threshold_type, hash_test_data in iter_hash_tests(*token_norm_args):\n",
    "    if threshold_type not in token_norm_results:\n",
    "        token_norm_results[threshold_type] = TestResultsSummary()\n",
    "    token_norm_results[threshold_type] = TestResultsSummary.merge_summaries(\n",
    "        token_norm_results[threshold_type],\n",
    "        run_hash_tests(hash_test_data)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "73e973e7df5cfa25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T00:34:41.193164Z",
     "start_time": "2024-05-11T00:34:41.178664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>FAR</th>\n",
       "      <th>FRR</th>\n",
       "      <th>HTER</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371747</td>\n",
       "      <td>0.185874</td>\n",
       "      <td>0.814126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371747</td>\n",
       "      <td>0.185874</td>\n",
       "      <td>0.814126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.572491</td>\n",
       "      <td>0.286245</td>\n",
       "      <td>0.713755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.576208</td>\n",
       "      <td>0.288104</td>\n",
       "      <td>0.711896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.576208</td>\n",
       "      <td>0.288104</td>\n",
       "      <td>0.711896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.576208</td>\n",
       "      <td>0.288104</td>\n",
       "      <td>0.711896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.576208</td>\n",
       "      <td>0.288104</td>\n",
       "      <td>0.711896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.576208</td>\n",
       "      <td>0.288104</td>\n",
       "      <td>0.711896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.576208</td>\n",
       "      <td>0.288104</td>\n",
       "      <td>0.711896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold  FAR       FRR      HTER  Accuracy\n",
       "0         10  0.0  0.371747  0.185874  0.814126\n",
       "1         20  0.0  0.371747  0.185874  0.814126\n",
       "2         30  0.0  0.572491  0.286245  0.713755\n",
       "3         40  0.0  0.576208  0.288104  0.711896\n",
       "4         50  0.0  0.576208  0.288104  0.711896\n",
       "5         60  0.0  0.576208  0.288104  0.711896\n",
       "6         70  0.0  0.576208  0.288104  0.711896\n",
       "7         80  0.0  0.576208  0.288104  0.711896\n",
       "8         90  0.0  0.576208  0.288104  0.711896"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_norm_data = []\n",
    "for threshold_type, result_summary in token_norm_results.items():\n",
    "    token_norm_data.append([\n",
    "        threshold_type, result_summary.false_accept_rate, \n",
    "        result_summary.false_reject_rate, result_summary.half_total_error_rate, \n",
    "        result_summary.accuracy\n",
    "    ])\n",
    "token_norm_df = pd.DataFrame(token_norm_data, columns=['Threshold', 'FAR', 'FRR', 'HTER', 'Accuracy'])\n",
    "token_norm_df.sort_values(by='HTER', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683b6d17",
   "metadata": {},
   "source": [
    "# Simulated Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "63dc1fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_model_executions(test_data_map: typing.Dict[str, typing.List[np.ndarray]], \n",
    "                              tokens: typing.Dict[str, str], \n",
    "                              encoder: feature_encoding.base.BinaryEncoder) -> typing.Tuple[int, float, float]:\n",
    "    hashes: typing.List[typing.List[fuzzy_hash_lib.FuzzyHash]] = []\n",
    "    hash_timings: typing.List[float] = []\n",
    "    compare_timings: typing.List[float] = []\n",
    "    for subject, test_data in test_data_map.items():\n",
    "        sample_hashes: typing.List[fuzzy_hash_lib.FuzzyHash] = []\n",
    "        for test_sample in test_data:\n",
    "            if len(hash_timings) >= 20:\n",
    "                break\n",
    "            token = tokens[subject]\n",
    "            token_data_generator = orthonormalization.TokenDataGenerator(token)\n",
    "            normalizer = orthonormalization.TokenMatrixNormalization(token_data_generator)\n",
    "            hash_start = time.perf_counter()\n",
    "            normalized = normalizer.normalize(test_sample)\n",
    "            encoded = encoder.encode(normalized)\n",
    "            test_hash = fuzzy_hash_lib.FuzzyHash.from_text(encoded)\n",
    "            hash_end = time.perf_counter()\n",
    "            sample_hashes.append(test_hash)\n",
    "            hash_timings.append(hash_end - hash_start)\n",
    "        hashes.append(sample_hashes)\n",
    "    for hash_samples in hashes:\n",
    "        randomized_samples = [sample for sample in hash_samples]\n",
    "        random.shuffle(randomized_samples)\n",
    "        for sample, tester in zip(hash_samples, randomized_samples):\n",
    "            if len(compare_timings) >= 20:\n",
    "                break\n",
    "            compare_start = time.perf_counter()\n",
    "            fuzzy_hash_lib.FuzzyHash.compare(sample, tester)\n",
    "            compare_end = time.perf_counter()\n",
    "            compare_timings.append(compare_end - compare_start)\n",
    "    return len(hash_timings), statistics.mean(hash_timings), statistics.mean(compare_timings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "38428a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashes computed and compared: 20\n",
      "Average hash time: 0.004326419298013207 seconds\n",
      "Average compare time: 5.319174815667793e-05 seconds\n"
     ]
    }
   ],
   "source": [
    "hash_count, average_hash_time, average_compare_time = simulate_model_executions(processed_data_map, tokens_map, threshold_encoder)\n",
    "print(f\"Hashes computed and compared: {hash_count}\")\n",
    "print(f\"Average hash time: {average_hash_time} seconds\")\n",
    "print(f\"Average compare time: {average_compare_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
