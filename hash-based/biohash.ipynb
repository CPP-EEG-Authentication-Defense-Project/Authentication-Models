{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da4f13ce619dc02a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Setup\n",
    "\n",
    "Initial module setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dbb2b529fba557",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:23.130629Z",
     "start_time": "2024-04-04T03:33:17.327122Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import dataclasses\n",
    "import enum\n",
    "import typing\n",
    "import random\n",
    "import secrets\n",
    "import time\n",
    "import statistics\n",
    "import auth_biohash.bio_hash\n",
    "import feature_encoding.base\n",
    "import feature_encoding.threshold\n",
    "import feature_encoding.direct\n",
    "import feature_encoding.gray\n",
    "\n",
    "from eeg_auth_models_framework import data, pre_process, features, processor, normalization\n",
    "from eeg_auth_models_framework.utils import conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aaec4b61b22133",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeed6ee7832bc937",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:23.146091Z",
     "start_time": "2024-04-04T03:33:23.132130Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AUTHENTICATION_THRESHOLDS = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "DATASET_SAMPLE_FREQ_HZ = 200\n",
    "DATA_CHANNEL_NAMES = ['T7','F8','Cz','P4']\n",
    "FREQUENCIES = [\n",
    "    pre_process.FrequencyBand(lower=8.0, upper=12.0, label='Alpha'),\n",
    "    pre_process.FrequencyBand(lower=12.0, upper=35.0, label='Beta'),\n",
    "    pre_process.FrequencyBand(lower=4.0, upper=8.0, label='Theta'),\n",
    "    pre_process.FrequencyBand(lower=35.0, upper=None, label='Gamma'),\n",
    "    pre_process.FrequencyBand(lower=None, upper=None, label='Raw'),\n",
    "]\n",
    "RESCALE_LOWER = 0\n",
    "RESCALE_UPPER = 255\n",
    "WINDOW_SIZE = 1200\n",
    "WINDOW_OVERLAP = 0\n",
    "BINARY_THRESHOLD = 50\n",
    "RANDOM_SEED = 100000000000\n",
    "RANDOM_GENERATOR = random.Random(RANDOM_SEED)\n",
    "SYSTEMIC_SAMPLE_RATE = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bda9cd27dc1c7d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87196d459e581a50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:23.161595Z",
     "start_time": "2024-04-04T03:33:23.147095Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TestResultType(enum.Enum):\n",
    "    TRUE_POSITIVE = enum.auto()\n",
    "    FALSE_POSITIVE = enum.auto()\n",
    "    FALSE_NEGATIVE = enum.auto()\n",
    "    TRUE_NEGATIVE = enum.auto()\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class TestResultsSummary:\n",
    "    true_positives: int = 0\n",
    "    false_positives: int = 0\n",
    "    false_negatives: int = 0\n",
    "    true_negatives: int = 0\n",
    "    \n",
    "    @classmethod\n",
    "    def merge_summaries(cls, \n",
    "                        summary_a: 'TestResultsSummary', \n",
    "                        summary_b: 'TestResultsSummary') -> 'TestResultsSummary':\n",
    "        return TestResultsSummary(\n",
    "            true_positives=summary_a.true_positives + summary_b.true_positives,\n",
    "            false_positives=summary_a.false_positives + summary_b.false_positives,\n",
    "            false_negatives=summary_a.false_negatives + summary_b.false_negatives,\n",
    "            true_negatives=summary_a.true_negatives + summary_b.true_negatives\n",
    "        )\n",
    "    \n",
    "    def increment_count(self, result_type: TestResultType):\n",
    "        if result_type == TestResultType.TRUE_POSITIVE:\n",
    "            self.true_positives += 1\n",
    "        elif result_type == TestResultType.FALSE_POSITIVE:\n",
    "            self.false_positives += 1\n",
    "        elif result_type == TestResultType.FALSE_NEGATIVE:\n",
    "            self.false_negatives += 1\n",
    "        else:\n",
    "            self.true_negatives += 1\n",
    "    \n",
    "    @property\n",
    "    def accuracy(self) -> float:\n",
    "        hits = self.true_positives + self.true_negatives\n",
    "        total = (\n",
    "            self.true_positives + self.true_negatives + \n",
    "            self.false_positives + self.false_negatives\n",
    "        )\n",
    "        return hits / total\n",
    "\n",
    "    @property\n",
    "    def false_accept_rate(self) -> float:\n",
    "        return self.false_positives / (self.false_positives + self.true_negatives)\n",
    "    \n",
    "    @property\n",
    "    def false_reject_rate(self):\n",
    "        return self.false_negatives / (self.false_negatives + self.true_positives)\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class HashTest:\n",
    "    expected_result: bool\n",
    "    threshold: float\n",
    "    if_expected: TestResultType\n",
    "    if_unexpected: TestResultType\n",
    "    hashes: typing.Tuple[auth_biohash.bio_hash.BioHash, auth_biohash.bio_hash.BioHash]\n",
    "    \n",
    "    def run_test(self) -> TestResultType:\n",
    "        result = auth_biohash.bio_hash.BioHash.compare(\n",
    "            self.hashes[0],\n",
    "            self.hashes[1]\n",
    "        )\n",
    "        is_match = result <= self.threshold\n",
    "        if is_match != self.expected_result:\n",
    "            return self.if_unexpected\n",
    "        return self.if_expected\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class ThresholdTestSet:\n",
    "    threshold: str\n",
    "    template_hash: auth_biohash.bio_hash.BioHash\n",
    "    positive_cases: typing.List[auth_biohash.bio_hash.BioHash]\n",
    "    negative_cases: typing.List[auth_biohash.bio_hash.BioHash]\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class SubjectTestSet:\n",
    "    subject_id: str\n",
    "    threshold_tests: typing.List[ThresholdTestSet]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac0435ab0259cc6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7579517532835c5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:23.177095Z",
     "start_time": "2024-04-04T03:33:23.162595Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "downloader = data.AuditoryDataDownloader()\n",
    "reader = data.AuditoryDataReader()\n",
    "converter = conversion.MNEDataFrameConverter(\n",
    "    channels=DATA_CHANNEL_NAMES, \n",
    "    sample_frequency=DATASET_SAMPLE_FREQ_HZ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fc4ed2b371256f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Processing Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a25e7c77d6f1c5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Template Hash Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b96cc069323e4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Pre-Processing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7efbdfd5a13740e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:23.192628Z",
     "start_time": "2024-04-04T03:33:23.179095Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "template_pre_process_steps = pre_process.PreProcessingPipeline([\n",
    "    pre_process.EEGBandpassFilterStep(\n",
    "        FREQUENCIES,\n",
    "        converter\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99e6996522d9c29",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Feature Extraction Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9704959409db63bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:23.208128Z",
     "start_time": "2024-04-04T03:33:23.193628Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "template_feature_extraction_steps = features.FeatureExtractPipeline([\n",
    "    features.StatisticalFeatureExtractor([\n",
    "        features.StatisticalFeature.MIN,\n",
    "        features.StatisticalFeature.MAX,\n",
    "        features.StatisticalFeature.MEAN,\n",
    "        features.StatisticalFeature.ZERO_CROSSING_RATE\n",
    "    ])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2172e31d2ed05717",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Normalization Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42ff144029c56cca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:23.223629Z",
     "start_time": "2024-04-04T03:33:23.209128Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "template_normalization_steps = normalization.NormalizationPipeline([\n",
    "    normalization.RescaleNormalizationStep(RESCALE_LOWER, RESCALE_UPPER),\n",
    "    normalization.HistogramEqualizationStep(RESCALE_LOWER, RESCALE_UPPER)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d849dc2ada492d85",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1442faa54098f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:23.239165Z",
     "start_time": "2024-04-04T03:33:23.224628Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "template_data_processor = processor.DataProcessor(\n",
    "    pre_process=template_pre_process_steps,\n",
    "    feature_extraction=template_feature_extraction_steps,\n",
    "    normalization=template_normalization_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993a651822b6459e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Sample Hash Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b527d47c1f13033",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Pre-Processing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b12f85a89a924fdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:23.254664Z",
     "start_time": "2024-04-04T03:33:23.240666Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_pre_process_steps = pre_process.PreProcessingPipeline([\n",
    "    pre_process.EEGBandpassFilterStep(\n",
    "        FREQUENCIES,\n",
    "        converter\n",
    "    ),\n",
    "    pre_process.DataWindowStep(WINDOW_SIZE, WINDOW_OVERLAP)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297f5a69a316f5b8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Feature Extraction Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ead5ce50ad8e4a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:23.270157Z",
     "start_time": "2024-04-04T03:33:23.255666Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_feature_extraction_steps = features.FeatureExtractPipeline([\n",
    "    features.StatisticalFeatureExtractor([\n",
    "        features.StatisticalFeature.MIN,\n",
    "        features.StatisticalFeature.MAX,\n",
    "        features.StatisticalFeature.MEAN,\n",
    "        features.StatisticalFeature.ZERO_CROSSING_RATE\n",
    "    ])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fa07fd6d349d685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:23.285661Z",
     "start_time": "2024-04-04T03:33:23.271157Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalization_steps = normalization.NormalizationPipeline([\n",
    "    normalization.RescaleNormalizationStep(RESCALE_LOWER, RESCALE_UPPER),\n",
    "    normalization.HistogramEqualizationStep(RESCALE_LOWER, RESCALE_UPPER)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c2f7c7de2ccd2a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96cda2e2a18aec21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:23.301157Z",
     "start_time": "2024-04-04T03:33:23.286658Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_data_processor = processor.DataProcessor(\n",
    "    pre_process=sample_pre_process_steps,\n",
    "    feature_extraction=sample_feature_extraction_steps,\n",
    "    normalization=normalization_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad82ca1877854ce6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Subject Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b76c562",
   "metadata": {},
   "outputs": [],
   "source": [
    "RawDataMap = typing.Dict[str, typing.List[pd.DataFrame]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96aacad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_test_maps(data_map: RawDataMap) -> typing.Tuple[RawDataMap, RawDataMap]:\n",
    "    result_training = {}\n",
    "    result_test = {}\n",
    "\n",
    "    for subject in data_map:\n",
    "        result_training[subject] = []\n",
    "        result_test[subject] = []\n",
    "        for frame_data in data_map[subject]:\n",
    "            training_frame, test_frame = make_training_test_frames(frame_data)\n",
    "            result_training[subject].append(training_frame)\n",
    "            result_test[subject].append(test_frame)\n",
    "\n",
    "    return result_training, result_test\n",
    "\n",
    "\n",
    "def make_training_test_frames(frame: pd.DataFrame) -> typing.Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    training = frame[::SYSTEMIC_SAMPLE_RATE]\n",
    "    test = frame.drop(training.index)\n",
    "    return training, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65c233cea5cfefda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:23.642172Z",
     "start_time": "2024-04-04T03:33:23.302159Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = downloader.retrieve()\n",
    "subject_data_map = reader.format_data(data_path)\n",
    "subject_data_train, subject_data_test = make_training_test_maps(subject_data_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c873a699c65e119",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Token Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2163f478debcf65d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:23.657670Z",
     "start_time": "2024-04-04T03:33:23.645169Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subject_tokens_map = {subject: secrets.token_hex(64) for subject in subject_data_map}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4971ba34eabb90",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Template Hash Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e17726ec1164985",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7249c199623f435",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:24.804668Z",
     "start_time": "2024-04-04T03:33:23.659171Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=13372\n",
      "    Range : 0 ... 13371 =      0.000 ...    66.855 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=8000\n",
      "    Range : 0 ... 7999 =      0.000 ...    39.995 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "processed_template_data_map = {subject: template_data_processor.process(subject_data_train[subject]) for subject in subject_data_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdac03a48bf5821",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40507f75e61dc604",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:24.820168Z",
     "start_time": "2024-04-04T03:33:24.806170Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SubjectHashesMap = typing.Dict[str, typing.Dict[str, typing.List[auth_biohash.bio_hash.BioHash]]]\n",
    "SubjectTemplateHashesMap = typing.Dict[str, typing.Dict[str, auth_biohash.bio_hash.BioHash]]\n",
    "ThresholdHashesMap = typing.Dict[str, typing.List[auth_biohash.bio_hash.BioHash]]\n",
    "TemplateHashesMap = typing.Dict[str, auth_biohash.bio_hash.BioHash]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94ef067b3ef633b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:24.835668Z",
     "start_time": "2024-04-04T03:33:24.821670Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_map_of_threshold_hashes(vectors_to_hash: typing.List[np.ndarray], \n",
    "                                 token: str, \n",
    "                                 encoder: feature_encoding.base.BinaryEncoder,\n",
    "                                 additional_norm: normalization.NormalizationPipeline = None) -> ThresholdHashesMap:\n",
    "    result = {}\n",
    "    for threshold in AUTHENTICATION_THRESHOLDS:\n",
    "        result[str(threshold)] = [\n",
    "            auth_biohash.bio_hash.BioHash.generate_hash(vector, token, encoder, additional_norm)\n",
    "            for vector in vectors_to_hash\n",
    "        ]\n",
    "    return result\n",
    "\n",
    "\n",
    "def iter_template_hashes(template_data_map: typing.Dict[str, typing.List[np.ndarray]],\n",
    "                         tokens_map: typing.Dict[str, str],\n",
    "                         encoder: feature_encoding.base.BinaryEncoder,\n",
    "                         additional_norm: normalization.NormalizationPipeline = None) -> typing.Iterator[typing.Tuple[str, TemplateHashesMap]]:\n",
    "    for subject in template_data_map:\n",
    "        token = tokens_map[subject]\n",
    "        template_hashes = make_map_of_threshold_hashes(\n",
    "            template_data_map[subject], token, encoder, additional_norm\n",
    "        )\n",
    "        normalized_hashes_map: TemplateHashesMap = {}\n",
    "        for threshold in template_hashes:\n",
    "            hashes_list = template_hashes[threshold]\n",
    "            if len(hashes_list) != 1:\n",
    "                print(f'[warning] Multiple hashes for subject {subject}, should be only 1.')\n",
    "                continue\n",
    "            normalized_hashes_map[threshold] = hashes_list[0]\n",
    "        yield subject, normalized_hashes_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c09d95332c4e738",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Sample Hash Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5513fde2d0127e36",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45137623ff340cd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:27.455168Z",
     "start_time": "2024-04-04T03:33:24.837170Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=26742\n",
      "    Range : 0 ... 26741 =      0.000 ...   133.705 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=16000\n",
      "    Range : 0 ... 15999 =      0.000 ...    79.995 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "processed_data_map = {subject: sample_data_processor.process(subject_data_test[subject]) for subject in subject_data_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256aa1a8ad30843c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d33a2abeab05d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:27.470667Z",
     "start_time": "2024-04-04T03:33:27.456169Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ThresholdHashesMap = typing.Dict[str, typing.List[auth_biohash.bio_hash.BioHash]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14da2c7c5e7e9927",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:27.486168Z",
     "start_time": "2024-04-04T03:33:27.472170Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def iter_sample_hashes(data_map: typing.Dict[str, typing.List[np.ndarray]], \n",
    "                       tokens_map: typing.Dict[str, str], \n",
    "                       encoder: feature_encoding.base.BinaryEncoder,\n",
    "                       additional_norm: normalization.NormalizationPipeline = None) -> typing.Iterator[typing.Tuple[str, ThresholdHashesMap]]:\n",
    "    for subject in data_map:\n",
    "        token = tokens_map[subject]\n",
    "        hashes_map = make_map_of_threshold_hashes(\n",
    "            data_map[subject], token, encoder, additional_norm\n",
    "        )\n",
    "        yield subject, hashes_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532edd13a1d7457e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Test Set Assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d16952f33d8817",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Gathering Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ce8c1346f775742",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:27.501672Z",
     "start_time": "2024-04-04T03:33:27.487170Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def iter_subject_test_sets(template_data: typing.Dict[str, typing.List[np.ndarray]],\n",
    "                           sample_data: typing.Dict[str, typing.List[np.ndarray]],\n",
    "                           tokens_map: typing.Dict[str, str],\n",
    "                           encoder: feature_encoding.base.BinaryEncoder,\n",
    "                           additional_norm: normalization.NormalizationPipeline = None) -> typing.Iterator[SubjectTestSet]:\n",
    "    for subject, template_hashes in iter_template_hashes(template_data, tokens_map, encoder, additional_norm):\n",
    "        threshold_test_sets: typing.Dict[str, ThresholdTestSet] = {\n",
    "            str(threshold): ThresholdTestSet(\n",
    "                threshold=threshold, template_hash=template_hashes[str(threshold)],\n",
    "                positive_cases=[], negative_cases=[]\n",
    "            )\n",
    "            for threshold in AUTHENTICATION_THRESHOLDS\n",
    "        }\n",
    "        for sample_subject, sample_hashes in iter_sample_hashes(sample_data, tokens_map, encoder, additional_norm):\n",
    "            for threshold in sample_hashes:\n",
    "                test_set = threshold_test_sets[threshold]\n",
    "                if subject == sample_subject:\n",
    "                    test_set.positive_cases.extend(sample_hashes[threshold])\n",
    "                else:\n",
    "                    test_set.negative_cases.extend(sample_hashes[threshold])\n",
    "        yield SubjectTestSet(\n",
    "            subject_id=subject,\n",
    "            threshold_tests=list(threshold_test_sets.values())\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30295b6e9df77a1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generating Hash Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3e62523ba531ace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:27.517203Z",
     "start_time": "2024-04-04T03:33:27.502668Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_hash_tests(test_set: ThresholdTestSet) -> typing.List[HashTest]:\n",
    "    tests = []\n",
    "    # Use the minimum to ensure that the same amount of tests are possible from both populations\n",
    "    # (there are more than likely more negative cases than positive ones)\n",
    "    sample_size = min(len(test_set.positive_cases), len(test_set.negative_cases))\n",
    "    should_match_cases: typing.List[auth_biohash.bio_hash.BioHash] = RANDOM_GENERATOR.sample(test_set.positive_cases, sample_size)\n",
    "    should_not_match_cases: typing.List[auth_biohash.bio_hash.BioHash] = RANDOM_GENERATOR.sample(test_set.negative_cases, sample_size)\n",
    "    for case in should_match_cases:\n",
    "        tests.append(\n",
    "            HashTest(\n",
    "                expected_result=True, \n",
    "                hashes=(test_set.template_hash, case),\n",
    "                threshold=float(test_set.threshold),\n",
    "                if_expected=TestResultType.TRUE_POSITIVE,\n",
    "                if_unexpected=TestResultType.FALSE_NEGATIVE\n",
    "            )\n",
    "        )\n",
    "    for case in should_not_match_cases:\n",
    "        tests.append(\n",
    "            HashTest(\n",
    "                expected_result=False, \n",
    "                hashes=(test_set.template_hash, case),\n",
    "                threshold=float(test_set.threshold),\n",
    "                if_expected=TestResultType.TRUE_NEGATIVE,\n",
    "                if_unexpected=TestResultType.FALSE_POSITIVE\n",
    "            )\n",
    "        )\n",
    "    return tests\n",
    "\n",
    "\n",
    "def iter_hash_tests(template_data: typing.Dict[str, typing.List[np.ndarray]],\n",
    "                    sample_data: typing.Dict[str, typing.List[np.ndarray]],\n",
    "                    tokens_map: typing.Dict[str, str],\n",
    "                    encoder: feature_encoding.base.BinaryEncoder,\n",
    "                    additional_norm: normalization.NormalizationPipeline = None) -> typing.Iterator[typing.Tuple[str, typing.List[HashTest]]]:\n",
    "    for subject_test_set in iter_subject_test_sets(template_data, sample_data, tokens_map, encoder, additional_norm):\n",
    "        for threshold_test_data in subject_test_set.threshold_tests:\n",
    "            yield threshold_test_data.threshold, make_hash_tests(threshold_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7640bc382687a81",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Execute Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "406fca59a9a6de2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:33:27.532706Z",
     "start_time": "2024-04-04T03:33:27.518209Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_hash_tests(hash_tests: typing.List[HashTest]) -> TestResultsSummary:\n",
    "    summary = TestResultsSummary()\n",
    "    for test in hash_tests:\n",
    "        result_type = test.run_test()\n",
    "        summary.increment_count(result_type)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a2220951fe0030",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Threshold-Based Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "254edaf47ec40792",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:37:32.364207Z",
     "start_time": "2024-04-04T03:33:27.533709Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threshold_results_map = {}\n",
    "threshold_encoder = feature_encoding.threshold.ThresholdBinaryEncoder(BINARY_THRESHOLD)\n",
    "threshold_test_args = (\n",
    "    processed_template_data_map, processed_data_map, subject_tokens_map, threshold_encoder\n",
    ")\n",
    "for auth_threshold, hash_test_data in iter_hash_tests(*threshold_test_args):\n",
    "    if auth_threshold not in threshold_results_map:\n",
    "        threshold_results_map[auth_threshold] = TestResultsSummary()\n",
    "    threshold_results_map[auth_threshold] = TestResultsSummary.merge_summaries(\n",
    "        threshold_results_map[auth_threshold],\n",
    "        run_hash_tests(hash_test_data)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c86f556fa5f1672b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:37:32.379707Z",
     "start_time": "2024-04-04T03:37:32.365208Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>FAR</th>\n",
       "      <th>FRR</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048327</td>\n",
       "      <td>0.975836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.100372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.949814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.821561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.589219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold       FAR       FRR  Accuracy\n",
       "0        0.1  0.000000  0.048327  0.975836\n",
       "1        0.2  0.000000  0.000000  1.000000\n",
       "2        0.3  0.003717  0.000000  0.998141\n",
       "3        0.4  0.100372  0.000000  0.949814\n",
       "4        0.5  0.821561  0.000000  0.589219\n",
       "5        0.6  1.000000  0.000000  0.500000\n",
       "6        0.7  1.000000  0.000000  0.500000\n",
       "7        0.8  1.000000  0.000000  0.500000\n",
       "8        0.9  1.000000  0.000000  0.500000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_results = []\n",
    "for auth_threshold, result_summary in threshold_results_map.items():\n",
    "    threshold_results.append([\n",
    "        auth_threshold, result_summary.false_accept_rate, \n",
    "        result_summary.false_reject_rate, result_summary.accuracy\n",
    "    ])\n",
    "threshold_df = pd.DataFrame(\n",
    "    threshold_results, columns=['Threshold', 'FAR', 'FRR', 'Accuracy']\n",
    ")\n",
    "threshold_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cded6e573b533d3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Direct Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11d661e8045f7155",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:41:51.782467Z",
     "start_time": "2024-04-04T03:37:32.380709Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "direct_results_map = {}\n",
    "direct_encoder = feature_encoding.direct.DirectBinaryEncoder()\n",
    "direct_test_args = (\n",
    "    processed_template_data_map, processed_data_map, subject_tokens_map, direct_encoder\n",
    ")\n",
    "for auth_threshold, hash_test_data in iter_hash_tests(*direct_test_args):\n",
    "    if auth_threshold not in direct_results_map:\n",
    "        direct_results_map[auth_threshold] = TestResultsSummary()\n",
    "    direct_results_map[auth_threshold] = TestResultsSummary.merge_summaries(\n",
    "        direct_results_map[auth_threshold],\n",
    "        run_hash_tests(hash_test_data)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c902a01bc47c30ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:41:51.797967Z",
     "start_time": "2024-04-04T03:41:51.783467Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>FAR</th>\n",
       "      <th>FRR</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.052045</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.972119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold       FAR       FRR  Accuracy\n",
       "0        0.1  0.000000  1.000000  0.500000\n",
       "1        0.2  0.000000  1.000000  0.500000\n",
       "2        0.3  0.000000  1.000000  0.500000\n",
       "3        0.4  0.052045  0.003717  0.972119\n",
       "4        0.5  1.000000  0.000000  0.500000\n",
       "5        0.6  1.000000  0.000000  0.500000\n",
       "6        0.7  1.000000  0.000000  0.500000\n",
       "7        0.8  1.000000  0.000000  0.500000\n",
       "8        0.9  1.000000  0.000000  0.500000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direct_results = []\n",
    "for auth_threshold, result_summary in direct_results_map.items():\n",
    "    direct_results.append([\n",
    "        auth_threshold, result_summary.false_accept_rate, \n",
    "        result_summary.false_reject_rate, result_summary.accuracy\n",
    "    ])\n",
    "direct_df = pd.DataFrame(\n",
    "    direct_results, columns=['Threshold', 'FAR', 'FRR', 'Accuracy']\n",
    ")\n",
    "direct_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520cef5e0acd21d5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Gray Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5f169a6bae686df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:46:05.339467Z",
     "start_time": "2024-04-04T03:41:51.798967Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gray_results_map = {}\n",
    "gray_encoder = feature_encoding.gray.GrayCodeBinaryEncoder(n=8, round_to_whole=True)\n",
    "codebook_normalization = normalization.NormalizationPipeline([\n",
    "    normalization.RescaleNormalizationStep(RESCALE_LOWER, RESCALE_UPPER),\n",
    "])\n",
    "gray_test_args = (\n",
    "    processed_template_data_map, processed_data_map, \n",
    "    subject_tokens_map, gray_encoder, codebook_normalization\n",
    ")\n",
    "for auth_threshold, hash_test_data in iter_hash_tests(*gray_test_args):\n",
    "    if auth_threshold not in gray_results_map:\n",
    "        gray_results_map[auth_threshold] = TestResultsSummary()\n",
    "    gray_results_map[auth_threshold] = TestResultsSummary.merge_summaries(\n",
    "        gray_results_map[auth_threshold],\n",
    "        run_hash_tests(hash_test_data)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce7061eb7147f42e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T03:46:05.354968Z",
     "start_time": "2024-04-04T03:46:05.340467Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>FAR</th>\n",
       "      <th>FRR</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405204</td>\n",
       "      <td>0.797398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159851</td>\n",
       "      <td>0.920074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.855019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.572491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold       FAR       FRR  Accuracy\n",
       "0        0.1  0.000000  1.000000  0.500000\n",
       "1        0.2  0.000000  0.405204  0.797398\n",
       "2        0.3  0.000000  0.159851  0.920074\n",
       "3        0.4  0.000000  0.000000  1.000000\n",
       "4        0.5  0.855019  0.000000  0.572491\n",
       "5        0.6  1.000000  0.000000  0.500000\n",
       "6        0.7  1.000000  0.000000  0.500000\n",
       "7        0.8  1.000000  0.000000  0.500000\n",
       "8        0.9  1.000000  0.000000  0.500000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_results = []\n",
    "for auth_threshold, result_summary in gray_results_map.items():\n",
    "    gray_results.append([\n",
    "        auth_threshold, result_summary.false_accept_rate, \n",
    "        result_summary.false_reject_rate, result_summary.accuracy\n",
    "    ])\n",
    "gray_df = pd.DataFrame(\n",
    "    gray_results, columns=['Threshold', 'FAR', 'FRR', 'Accuracy']\n",
    ")\n",
    "gray_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3930398",
   "metadata": {},
   "source": [
    "# Simulated Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c43145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_model_executions(test_data_map: typing.Dict[str, typing.List[np.ndarray]], \n",
    "                              tokens: typing.Dict[str, str], \n",
    "                              encoder: feature_encoding.base.BinaryEncoder, \n",
    "                              additional_norm: normalization.NormalizationPipeline = None) -> typing.Tuple[int, float, float]:\n",
    "    hashes: typing.List[typing.List[auth_biohash.bio_hash.BioHash]] = []\n",
    "    hash_timings: typing.List[float] = []\n",
    "    compare_timings: typing.List[float] = []\n",
    "    for subject, test_data in test_data_map.items():\n",
    "        sample_hashes: typing.List[auth_biohash.bio_hash.BioHash] = []\n",
    "        for test_sample in test_data:\n",
    "            hash_start = time.perf_counter()\n",
    "            test_hash = auth_biohash.bio_hash.BioHash.generate_hash(\n",
    "                test_sample, tokens[subject], encoder, additional_norm\n",
    "            )\n",
    "            hash_end = time.perf_counter()\n",
    "            sample_hashes.append(test_hash)\n",
    "            hash_timings.append(hash_end - hash_start)\n",
    "        hashes.append(sample_hashes)\n",
    "    for hash_samples in hashes:\n",
    "        randomized_samples = [sample for sample in hash_samples]\n",
    "        random.shuffle(randomized_samples)\n",
    "        for sample, tester in zip(hash_samples, randomized_samples):\n",
    "            compare_start = time.perf_counter()\n",
    "            auth_biohash.bio_hash.BioHash.compare(sample, tester)\n",
    "            compare_end = time.perf_counter()\n",
    "            compare_timings.append(compare_end - compare_start)\n",
    "    return len(hash_timings), statistics.mean(hash_timings), statistics.mean(compare_timings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b1170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_count, average_hash_time, average_compare_time = simulate_model_executions(processed_data_map, subject_tokens_map, threshold_encoder)\n",
    "print(f\"Hashes computed and compared: {hash_count}\")\n",
    "print(f\"Average hash time: {average_hash_time} seconds\")\n",
    "print(f\"Average compare time: {average_compare_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
