{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup\n",
    "\n",
    "Initial module setup."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da4f13ce619dc02a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dataclasses\n",
    "import enum\n",
    "import typing\n",
    "import random\n",
    "import auth_biohash.bio_hash\n",
    "import auth_biohash.random_token\n",
    "import feature_encoding.base\n",
    "import feature_encoding.threshold\n",
    "\n",
    "from eeg_auth_models_framework import data, pre_process, features, processor\n",
    "from eeg_auth_models_framework.utils import conversion"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:00:57.820995Z",
     "start_time": "2024-04-01T00:00:57.808995Z"
    }
   },
   "id": "77dbb2b529fba557",
   "execution_count": 93
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Constants"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0aaec4b61b22133"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "AUTHENTICATION_THRESHOLDS = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "DATASET_SAMPLE_FREQ_HZ = 200\n",
    "DATA_CHANNEL_NAMES = ['T7','F8','Cz','P4']\n",
    "FREQUENCIES = [\n",
    "    pre_process.FrequencyBand(lower=8.0, upper=12.0, label='Alpha'),\n",
    "    pre_process.FrequencyBand(lower=12.0, upper=35.0, label='Beta'),\n",
    "    pre_process.FrequencyBand(lower=4.0, upper=8.0, label='Theta'),\n",
    "    pre_process.FrequencyBand(lower=35.0, upper=None, label='Gamma'),\n",
    "    pre_process.FrequencyBand(lower=None, upper=None, label='Raw'),\n",
    "]\n",
    "WINDOW_SIZE = 1200\n",
    "WINDOW_OVERLAP = 0\n",
    "BINARY_THRESHOLD = 50\n",
    "RANDOM_SEED = 100000000000\n",
    "RANDOM_GENERATOR = random.Random(RANDOM_SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:00:57.898494Z",
     "start_time": "2024-04-01T00:00:57.884495Z"
    }
   },
   "id": "aeed6ee7832bc937",
   "execution_count": 94
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utilities"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13bda9cd27dc1c7d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TestResultType(enum.Enum):\n",
    "    TRUE_POSITIVE = enum.auto()\n",
    "    FALSE_POSITIVE = enum.auto()\n",
    "    FALSE_NEGATIVE = enum.auto()\n",
    "    TRUE_NEGATIVE = enum.auto()\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class TestResultsSummary:\n",
    "    true_positives: int = 0\n",
    "    false_positives: int = 0\n",
    "    false_negatives: int = 0\n",
    "    true_negatives: int = 0\n",
    "    \n",
    "    @classmethod\n",
    "    def merge_summaries(cls, \n",
    "                        summary_a: 'TestResultsSummary', \n",
    "                        summary_b: 'TestResultsSummary') -> 'TestResultsSummary':\n",
    "        return TestResultsSummary(\n",
    "            true_positives=summary_a.true_positives + summary_b.true_positives,\n",
    "            false_positives=summary_a.false_positives + summary_b.false_positives,\n",
    "            false_negatives=summary_a.false_negatives + summary_b.false_negatives,\n",
    "            true_negatives=summary_a.true_negatives + summary_b.true_negatives\n",
    "        )\n",
    "    \n",
    "    def increment_count(self, result_type: TestResultType):\n",
    "        if result_type == TestResultType.TRUE_POSITIVE:\n",
    "            self.true_positives += 1\n",
    "        elif result_type == TestResultType.FALSE_POSITIVE:\n",
    "            self.false_positives += 1\n",
    "        elif result_type == TestResultType.FALSE_NEGATIVE:\n",
    "            self.false_negatives += 1\n",
    "        else:\n",
    "            self.true_negatives += 1\n",
    "    \n",
    "    @property\n",
    "    def accuracy(self) -> float:\n",
    "        hits = self.true_positives + self.true_negatives\n",
    "        total = (\n",
    "            self.true_positives + self.true_negatives + \n",
    "            self.false_positives + self.false_negatives\n",
    "        )\n",
    "        return hits / total\n",
    "\n",
    "    @property\n",
    "    def false_accept_rate(self) -> float:\n",
    "        return self.false_positives / (self.false_positives + self.true_negatives)\n",
    "    \n",
    "    @property\n",
    "    def false_reject_rate(self):\n",
    "        return self.false_negatives / (self.false_negatives + self.true_positives)\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class HashTest:\n",
    "    expected_result: bool\n",
    "    threshold: float\n",
    "    if_expected: TestResultType\n",
    "    if_unexpected: TestResultType\n",
    "    hashes: typing.Tuple[auth_biohash.bio_hash.BioHash, auth_biohash.bio_hash.BioHash]\n",
    "    \n",
    "    def run_test(self) -> TestResultType:\n",
    "        result = auth_biohash.bio_hash.BioHash.compare(\n",
    "            self.hashes[0],\n",
    "            self.hashes[1]\n",
    "        )\n",
    "        is_match = result <= self.threshold\n",
    "        if is_match != self.expected_result:\n",
    "            return self.if_unexpected\n",
    "        return self.if_expected\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class ThresholdTestSet:\n",
    "    threshold: str\n",
    "    template_hash: auth_biohash.bio_hash.BioHash\n",
    "    positive_cases: typing.List[auth_biohash.bio_hash.BioHash]\n",
    "    negative_cases: typing.List[auth_biohash.bio_hash.BioHash]\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class SubjectTestSet:\n",
    "    subject_id: str\n",
    "    threshold_tests: typing.List[ThresholdTestSet]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:00:57.913995Z",
     "start_time": "2024-04-01T00:00:57.900495Z"
    }
   },
   "id": "87196d459e581a50",
   "execution_count": 95
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Configuration"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ac0435ab0259cc6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "downloader = data.AuditoryDataDownloader()\n",
    "reader = data.AuditoryDataReader()\n",
    "converter = conversion.MNEDataFrameConverter(\n",
    "    channels=DATA_CHANNEL_NAMES, \n",
    "    sample_frequency=DATASET_SAMPLE_FREQ_HZ\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:00:57.929494Z",
     "start_time": "2024-04-01T00:00:57.915495Z"
    }
   },
   "id": "7579517532835c5a",
   "execution_count": 96
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Processing Setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72fc4ed2b371256f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Template Hash Processor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4a25e7c77d6f1c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pre-Processing Steps"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c8b96cc069323e4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "template_pre_process_steps = pre_process.PreProcessingPipeline([\n",
    "    pre_process.EEGBandpassFilterStep(\n",
    "        FREQUENCIES,\n",
    "        converter\n",
    "    )\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:00:57.944994Z",
     "start_time": "2024-04-01T00:00:57.931494Z"
    }
   },
   "id": "c7efbdfd5a13740e",
   "execution_count": 97
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Extraction Steps"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d99e6996522d9c29"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "template_feature_extraction_steps = features.FeatureExtractPipeline([\n",
    "    features.StatisticalFeatureExtractor([\n",
    "        features.StatisticalFeature.MIN,\n",
    "        features.StatisticalFeature.MAX,\n",
    "        features.StatisticalFeature.MEAN,\n",
    "        features.StatisticalFeature.ZERO_CROSSING_RATE\n",
    "    ])\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:00:57.960494Z",
     "start_time": "2024-04-01T00:00:57.945995Z"
    }
   },
   "id": "9704959409db63bb",
   "execution_count": 98
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Processor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d849dc2ada492d85"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "template_data_processor = processor.DataProcessor(\n",
    "    pre_process=template_pre_process_steps,\n",
    "    feature_extraction=template_feature_extraction_steps\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:00:57.975994Z",
     "start_time": "2024-04-01T00:00:57.961996Z"
    }
   },
   "id": "1442faa54098f6",
   "execution_count": 99
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample Hash Processor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "993a651822b6459e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pre-Processing Steps"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b527d47c1f13033"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_pre_process_steps = pre_process.PreProcessingPipeline([\n",
    "    pre_process.EEGBandpassFilterStep(\n",
    "        FREQUENCIES,\n",
    "        converter\n",
    "    ),\n",
    "    pre_process.DataWindowStep(WINDOW_SIZE, WINDOW_OVERLAP)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:00:57.991494Z",
     "start_time": "2024-04-01T00:00:57.976996Z"
    }
   },
   "id": "b12f85a89a924fdf",
   "execution_count": 100
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Extraction Steps"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "297f5a69a316f5b8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_feature_extraction_steps = features.FeatureExtractPipeline([\n",
    "    features.StatisticalFeatureExtractor([\n",
    "        features.StatisticalFeature.MIN,\n",
    "        features.StatisticalFeature.MAX,\n",
    "        features.StatisticalFeature.MEAN,\n",
    "        features.StatisticalFeature.ZERO_CROSSING_RATE\n",
    "    ])\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:00:58.006994Z",
     "start_time": "2024-04-01T00:00:57.992996Z"
    }
   },
   "id": "8ead5ce50ad8e4a3",
   "execution_count": 101
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Processor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6c2f7c7de2ccd2a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_data_processor = processor.DataProcessor(\n",
    "    pre_process=sample_pre_process_steps,\n",
    "    feature_extraction=sample_feature_extraction_steps\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:00:58.022494Z",
     "start_time": "2024-04-01T00:00:58.008498Z"
    }
   },
   "id": "96cda2e2a18aec21",
   "execution_count": 102
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Subject Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad82ca1877854ce6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_path = downloader.retrieve()\n",
    "subject_data_map = reader.format_data(data_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:00:58.437495Z",
     "start_time": "2024-04-01T00:00:58.024995Z"
    }
   },
   "id": "65c233cea5cfefda",
   "execution_count": 103
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Token Setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c873a699c65e119"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "subject_tokens_map = {subject: auth_biohash.random_token.generate_token() for subject in subject_data_map}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:00:58.456494Z",
     "start_time": "2024-04-01T00:00:58.443997Z"
    }
   },
   "id": "2163f478debcf65d",
   "execution_count": 104
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Template Hash Setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f4971ba34eabb90"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Processing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e17726ec1164985"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=40114\n",
      "    Range : 0 ... 40113 =      0.000 ...   200.565 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "processed_template_data_map = {subject: template_data_processor.process(subject_data_map[subject]) for subject in subject_data_map}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:00:59.432994Z",
     "start_time": "2024-04-01T00:00:58.457996Z"
    }
   },
   "id": "c7249c199623f435",
   "execution_count": 105
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hashing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bdac03a48bf5821"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "SubjectHashesMap = typing.Dict[str, typing.Dict[str, typing.List[auth_biohash.bio_hash.BioHash]]]\n",
    "SubjectTemplateHashesMap = typing.Dict[str, typing.Dict[str, auth_biohash.bio_hash.BioHash]]\n",
    "ThresholdHashesMap = typing.Dict[str, typing.List[auth_biohash.bio_hash.BioHash]]\n",
    "TemplateHashesMap = typing.Dict[str, auth_biohash.bio_hash.BioHash]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:00:59.448494Z",
     "start_time": "2024-04-01T00:00:59.434495Z"
    }
   },
   "id": "40507f75e61dc604",
   "execution_count": 106
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def make_map_of_threshold_hashes(vectors_to_hash: typing.List[np.ndarray], \n",
    "                                 token: str, \n",
    "                                 encoder: feature_encoding.base.BinaryEncoder) -> ThresholdHashesMap:\n",
    "    result = {}\n",
    "    for threshold in AUTHENTICATION_THRESHOLDS:\n",
    "        result[str(threshold)] = [\n",
    "            auth_biohash.bio_hash.BioHash.generate_hash(vector, token, encoder)\n",
    "            for vector in vectors_to_hash\n",
    "        ]\n",
    "    return result\n",
    "\n",
    "\n",
    "def iter_template_hashes(template_data_map: typing.Dict[str, typing.List[np.ndarray]],\n",
    "                         tokens_map: typing.Dict[str, str],\n",
    "                         encoder: feature_encoding.base.BinaryEncoder) -> typing.Iterator[typing.Tuple[str, TemplateHashesMap]]:\n",
    "    for subject in template_data_map:\n",
    "        token = tokens_map[subject]\n",
    "        template_hashes = make_map_of_threshold_hashes(template_data_map[subject], token, encoder)\n",
    "        normalized_hashes_map: TemplateHashesMap = {}\n",
    "        for threshold in template_hashes:\n",
    "            hashes_list = template_hashes[threshold]\n",
    "            if len(hashes_list) != 1:\n",
    "                print(f'[warning] Multiple hashes for subject {subject}, should be only 1.')\n",
    "                continue\n",
    "            normalized_hashes_map[threshold] = hashes_list[0]\n",
    "        yield subject, normalized_hashes_map"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:00:59.463994Z",
     "start_time": "2024-04-01T00:00:59.449494Z"
    }
   },
   "id": "94ef067b3ef633b0",
   "execution_count": 107
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample Hash Setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c09d95332c4e738"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Processing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5513fde2d0127e36"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=40114\n",
      "    Range : 0 ... 40113 =      0.000 ...   200.565 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=4, n_times=24000\n",
      "    Range : 0 ... 23999 =      0.000 ...   119.995 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "processed_data_map = {subject: sample_data_processor.process(subject_data_map[subject]) for subject in subject_data_map}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:01:02.191994Z",
     "start_time": "2024-04-01T00:00:59.465497Z"
    }
   },
   "id": "45137623ff340cd6",
   "execution_count": 108
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hashing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "256aa1a8ad30843c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ThresholdHashesMap = typing.Dict[str, typing.List[auth_biohash.bio_hash.BioHash]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:01:02.207549Z",
     "start_time": "2024-04-01T00:01:02.193495Z"
    }
   },
   "id": "6d33a2abeab05d8",
   "execution_count": 109
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def iter_sample_hashes(data_map: typing.Dict[str, typing.List[np.ndarray]], \n",
    "                       tokens_map: typing.Dict[str, str], \n",
    "                       encoder: feature_encoding.base.BinaryEncoder) -> typing.Iterator[typing.Tuple[str, ThresholdHashesMap]]:\n",
    "    for subject in data_map:\n",
    "        token = tokens_map[subject]\n",
    "        hashes_map = make_map_of_threshold_hashes(data_map[subject], token, encoder)\n",
    "        yield subject, hashes_map"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:01:02.222994Z",
     "start_time": "2024-04-01T00:01:02.208996Z"
    }
   },
   "id": "14da2c7c5e7e9927",
   "execution_count": 110
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Set Assembly"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "532edd13a1d7457e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gathering Test Sets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8d16952f33d8817"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def iter_subject_test_sets(template_data: typing.Dict[str, typing.List[np.ndarray]],\n",
    "                           sample_data: typing.Dict[str, typing.List[np.ndarray]],\n",
    "                           tokens_map: typing.Dict[str, str],\n",
    "                           encoder: feature_encoding.base.BinaryEncoder) -> typing.Iterator[SubjectTestSet]:\n",
    "    for subject, template_hashes in iter_template_hashes(template_data, tokens_map, encoder):\n",
    "        threshold_test_sets: typing.Dict[str, ThresholdTestSet] = {\n",
    "            str(threshold): ThresholdTestSet(\n",
    "                threshold=threshold, template_hash=template_hashes[str(threshold)],\n",
    "                positive_cases=[], negative_cases=[]\n",
    "            )\n",
    "            for threshold in AUTHENTICATION_THRESHOLDS\n",
    "        }\n",
    "        for sample_subject, sample_hashes in iter_sample_hashes(sample_data, tokens_map, encoder):\n",
    "            for threshold in sample_hashes:\n",
    "                test_set = threshold_test_sets[threshold]\n",
    "                if subject == sample_subject:\n",
    "                    test_set.positive_cases.extend(sample_hashes[threshold])\n",
    "                else:\n",
    "                    test_set.negative_cases.extend(sample_hashes[threshold])\n",
    "        yield SubjectTestSet(\n",
    "            subject_id=subject,\n",
    "            threshold_tests=list(threshold_test_sets.values())\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:01:02.238495Z",
     "start_time": "2024-04-01T00:01:02.224496Z"
    }
   },
   "id": "1ce8c1346f775742",
   "execution_count": 111
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generating Hash Tests"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f30295b6e9df77a1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def make_hash_tests(test_set: ThresholdTestSet) -> typing.List[HashTest]:\n",
    "    tests = []\n",
    "    # Use the minimum to ensure that the same amount of tests are possible from both populations\n",
    "    # (there are more than likely more negative cases than positive ones)\n",
    "    sample_size = min(len(test_set.positive_cases), len(test_set.negative_cases))\n",
    "    should_match_cases: typing.List[auth_biohash.bio_hash.BioHash] = RANDOM_GENERATOR.sample(test_set.positive_cases, sample_size)\n",
    "    should_not_match_cases: typing.List[auth_biohash.bio_hash.BioHash] = RANDOM_GENERATOR.sample(test_set.negative_cases, sample_size)\n",
    "    for case in should_match_cases:\n",
    "        tests.append(\n",
    "            HashTest(\n",
    "                expected_result=True, \n",
    "                hashes=(test_set.template_hash, case),\n",
    "                threshold=float(test_set.threshold),\n",
    "                if_expected=TestResultType.TRUE_POSITIVE,\n",
    "                if_unexpected=TestResultType.FALSE_NEGATIVE\n",
    "            )\n",
    "        )\n",
    "    for case in should_not_match_cases:\n",
    "        tests.append(\n",
    "            HashTest(\n",
    "                expected_result=False, \n",
    "                hashes=(test_set.template_hash, case),\n",
    "                threshold=float(test_set.threshold),\n",
    "                if_expected=TestResultType.TRUE_NEGATIVE,\n",
    "                if_unexpected=TestResultType.FALSE_POSITIVE\n",
    "            )\n",
    "        )\n",
    "    return tests\n",
    "\n",
    "\n",
    "def iter_hash_tests(template_data: typing.Dict[str, typing.List[np.ndarray]],\n",
    "                    sample_data: typing.Dict[str, typing.List[np.ndarray]],\n",
    "                    tokens_map: typing.Dict[str, str],\n",
    "                    encoder: feature_encoding.base.BinaryEncoder) -> typing.Iterator[typing.Tuple[str, typing.List[HashTest]]]:\n",
    "    for subject_test_set in iter_subject_test_sets(template_data, sample_data, tokens_map, encoder):\n",
    "        for threshold_test_data in subject_test_set.threshold_tests:\n",
    "            yield threshold_test_data.threshold, make_hash_tests(threshold_test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:01:02.253995Z",
     "start_time": "2024-04-01T00:01:02.239994Z"
    }
   },
   "id": "e3e62523ba531ace",
   "execution_count": 112
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Execute Tests"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7640bc382687a81"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def run_hash_tests(hash_tests: typing.List[HashTest]) -> TestResultsSummary:\n",
    "    summary = TestResultsSummary()\n",
    "    for test in hash_tests:\n",
    "        result_type = test.run_test()\n",
    "        summary.increment_count(result_type)\n",
    "    return summary"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:01:02.269496Z",
     "start_time": "2024-04-01T00:01:02.255996Z"
    }
   },
   "id": "35a901187cccf91f",
   "execution_count": 113
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_results_map = {}\n",
    "threshold_encoder = feature_encoding.threshold.ThresholdBinaryEncoder(BINARY_THRESHOLD)\n",
    "hash_test_args = (\n",
    "    processed_template_data_map, processed_data_map, subject_tokens_map, threshold_encoder\n",
    ")\n",
    "for threshold_type, hash_test_data in iter_hash_tests(*hash_test_args):\n",
    "    if threshold_type not in test_results_map:\n",
    "        test_results_map[threshold_type] = TestResultsSummary()\n",
    "    test_results_map[threshold_type] = TestResultsSummary.merge_summaries(\n",
    "        test_results_map[threshold_type],\n",
    "        run_hash_tests(hash_test_data)\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:05:08.311994Z",
     "start_time": "2024-04-01T00:01:02.272997Z"
    }
   },
   "id": "254edaf47ec40792",
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   Threshold       FAR       FRR  Accuracy\n0        0.1  0.000000  0.157385  0.921308\n1        0.2  0.000000  0.077482  0.961259\n2        0.3  0.000000  0.077482  0.961259\n3        0.4  0.038741  0.000000  0.980630\n4        0.5  0.527845  0.000000  0.736077\n5        0.6  0.963680  0.000000  0.518160\n6        0.7  0.997579  0.000000  0.501211\n7        0.8  1.000000  0.000000  0.500000\n8        0.9  1.000000  0.000000  0.500000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Threshold</th>\n      <th>FAR</th>\n      <th>FRR</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.1</td>\n      <td>0.000000</td>\n      <td>0.157385</td>\n      <td>0.921308</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.2</td>\n      <td>0.000000</td>\n      <td>0.077482</td>\n      <td>0.961259</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.3</td>\n      <td>0.000000</td>\n      <td>0.077482</td>\n      <td>0.961259</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.4</td>\n      <td>0.038741</td>\n      <td>0.000000</td>\n      <td>0.980630</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.5</td>\n      <td>0.527845</td>\n      <td>0.000000</td>\n      <td>0.736077</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.6</td>\n      <td>0.963680</td>\n      <td>0.000000</td>\n      <td>0.518160</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.7</td>\n      <td>0.997579</td>\n      <td>0.000000</td>\n      <td>0.501211</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.8</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.9</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_results = []\n",
    "for threshold_type, result_summary in test_results_map.items():\n",
    "    data_results.append([\n",
    "        threshold_type, result_summary.false_accept_rate, \n",
    "        result_summary.false_reject_rate, result_summary.accuracy\n",
    "    ])\n",
    "test_results = pd.DataFrame(\n",
    "    data_results, columns=['Threshold', 'FAR', 'FRR', 'Accuracy']\n",
    ")\n",
    "test_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:05:08.342995Z",
     "start_time": "2024-04-01T00:05:08.312994Z"
    }
   },
   "id": "c86f556fa5f1672b",
   "execution_count": 115
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T00:05:08.358494Z",
     "start_time": "2024-04-01T00:05:08.343994Z"
    }
   },
   "id": "3020e8047afbd850",
   "execution_count": 115
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
